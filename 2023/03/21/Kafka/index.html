<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Kafka   【Refer】 文档： 官网地址：https:&#x2F;&#x2F;kafka.apache.org&#x2F; 视频： https:&#x2F;&#x2F;www.bilibili.com&#x2F;video&#x2F;BV1vr4y1677k&#x2F;?spm_id_from&#x3D;333.337.search-card.all.click  kafka 入门Kafka 概述定义 Kafka 传统定义：Kafka 是一个分布式的基于发布&#x2F;订阅模式">
<meta property="og:type" content="article">
<meta property="og:title" content="Kafka">
<meta property="og:url" content="http://example.com/2023/03/21/Kafka/index.html">
<meta property="og:site_name" content="MineTing">
<meta property="og:description" content="Kafka   【Refer】 文档： 官网地址：https:&#x2F;&#x2F;kafka.apache.org&#x2F; 视频： https:&#x2F;&#x2F;www.bilibili.com&#x2F;video&#x2F;BV1vr4y1677k&#x2F;?spm_id_from&#x3D;333.337.search-card.all.click  kafka 入门Kafka 概述定义 Kafka 传统定义：Kafka 是一个分布式的基于发布&#x2F;订阅模式">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/2023/03/21/Kafka/Kafka%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-%E5%89%8A%E5%B3%B0.png">
<meta property="og:image" content="http://example.com/2023/03/21/Kafka/Kafka%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-%E8%A7%A3%E8%80%A6.png">
<meta property="og:image" content="http://example.com/2023/03/21/Kafka/Kafka%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-%E5%BC%82%E6%AD%A5.png">
<meta property="og:image" content="http://example.com/2023/03/21/Kafka/Kakfa%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-%E7%82%B9%E5%AF%B9%E7%82%B9%E6%A8%A1%E5%BC%8F.png">
<meta property="og:image" content="http://example.com/2023/03/21/Kafka/Kafka%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85%E6%A8%A1%E5%BC%8F.png">
<meta property="og:image" content="http://example.com/2023/03/21/Kafka/Kafka%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84.png">
<meta property="og:image" content="http://example.com/2023/03/21/Kafka/Kafka%E7%94%9F%E4%BA%A7%E8%80%85%E5%8F%91%E9%80%81%E6%B5%81%E7%A8%8B.png">
<meta property="og:image" content="http://example.com/2023/03/21/Kafka/Kafka%E5%88%86%E5%8C%BA%E4%BC%98%E7%82%B9.png">
<meta property="og:image" content="http://example.com/2023/03/21/Kafka/Kafka%E7%94%9F%E4%BA%A7%E8%80%85%E5%8F%91%E9%80%81%E6%B5%81%E7%A8%8B.png">
<meta property="og:image" content="http://example.com/2023/03/21/Kafka/ACK%E5%BA%94%E7%AD%94%E7%BA%A7%E5%88%AB0.png">
<meta property="og:image" content="http://example.com/2023/03/21/Kafka/ACK%20%E5%BA%94%E7%AD%94%E7%BA%A7%E5%88%AB1.png">
<meta property="og:image" content="http://example.com/2023/03/21/Kafka/ACK%20%E5%BA%94%E7%AD%94%E7%BA%A7%E5%88%ABall.png">
<meta property="og:image" content="http://example.com/2023/03/21/Kafka/ACK%E5%BA%94%E7%AD%94%E7%BA%A7%E5%88%AB%E4%B8%BAall%E6%97%B6%E6%95%B0%E6%8D%AE%E9%87%8D%E5%A4%8D.png">
<meta property="og:image" content="http://example.com/2023/03/21/Kafka/%E5%B9%82%E7%AD%89%E6%80%A7%E5%8E%9F%E7%90%86.png">
<meta property="og:image" content="http://example.com/2023/03/21/Kafka/%E7%94%9F%E4%BA%A7%E8%80%85%E4%BA%8B%E5%8A%A1%E5%8E%9F%E7%90%86.png">
<meta property="og:image" content="http://example.com/2023/03/21/Kafka/%E5%8D%95%E5%88%86%E5%8C%BA%E6%95%B0%E6%8D%AE%E6%9C%89%E5%BA%8F.png">
<meta property="og:image" content="http://example.com/2023/03/21/Kafka/%E6%95%B0%E6%8D%AE%E6%9C%89%E5%BA%8F.png">
<meta property="article:published_time" content="2023-03-20T16:00:00.000Z">
<meta property="article:modified_time" content="2023-06-09T06:40:24.033Z">
<meta property="article:author" content="Fei">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2023/03/21/Kafka/Kafka%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-%E5%89%8A%E5%B3%B0.png">

<link rel="canonical" href="http://example.com/2023/03/21/Kafka/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Kafka | MineTing</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">MineTing</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/03/21/Kafka/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Fei">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="MineTing">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Kafka
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-03-21 00:00:00" itemprop="dateCreated datePublished" datetime="2023-03-21T00:00:00+08:00">2023-03-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-06-09 14:40:24" itemprop="dateModified" datetime="2023-06-09T14:40:24+08:00">2023-06-09</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <div align="center"><font size="70"><b>Kafka</b></font></div>

<blockquote>
<p>【Refer】</p>
<p>文档：</p>
<p>官网地址：<a target="_blank" rel="noopener" href="https://kafka.apache.org/">https://kafka.apache.org/</a></p>
<p>视频：</p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1vr4y1677k/?spm_id_from=333.337.search-card.all.click">https://www.bilibili.com/video/BV1vr4y1677k/?spm_id_from=333.337.search-card.all.click</a></p>
</blockquote>
<h1 id="kafka-入门"><a href="#kafka-入门" class="headerlink" title="kafka 入门"></a>kafka 入门</h1><h2 id="Kafka-概述"><a href="#Kafka-概述" class="headerlink" title="Kafka 概述"></a>Kafka 概述</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><ul>
<li><p>Kafka 传统定义：<strong>Kafka 是一个分布式的基于发布&#x2F;订阅模式的消息队列（Message Queue）</strong>，主要应用于大数据实时处理领域。</p>
<p>发布&#x2F;订阅：消息的发布者不会将消息直接发送给特定的订阅者，而是将发布的消息 分为不同的类别，订阅者只接收感兴趣的消息。</p>
</li>
<li><p>Kafka 最新定义 ： <strong>Kafka是一个开源的分布式事件流平台 （Event Streaming Platform）</strong>，被数千家公司用于高性能数据管道、流分析、数据集成和关键任务应用。</p>
</li>
</ul>
<h3 id="消息队列"><a href="#消息队列" class="headerlink" title="消息队列"></a>消息队列</h3><p>消息队列，是消息也是队列；目前企业中常见的消息队列产品主要有 Kafka、ActiveMQ 、RabbitMQ 、 RocketMQ 等。</p>
<p>在大数据场景主要采用 Kafka 作为消息队列。在 JavaEE 开发中主要采用 ActiveMQ、 RabbitMQ、RocketMQ</p>
<h4 id="传统消息队列的应用场景"><a href="#传统消息队列的应用场景" class="headerlink" title="传统消息队列的应用场景"></a>传统消息队列的应用场景</h4><p>主要应用场景包括：缓存&#x2F;消峰、解耦和异步通信</p>
<ul>
<li><p>缓冲&#x2F;消峰：有助于控制和优化数据流经过系统的速度，解决生产消息和消费消息的处理速度不一致的情况。</p>
<p><img src="/2023/03/21/Kafka/Kafka%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-%E5%89%8A%E5%B3%B0.png" alt="Kafka消息队列-削峰.png"></p>
</li>
<li><p>解耦：允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。</p>
<p><img src="/2023/03/21/Kafka/Kafka%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-%E8%A7%A3%E8%80%A6.png" alt="Kafka消息队列-解耦.png"></p>
</li>
<li><p>异步通信：允许用户把一个消息放入队列，但并不立即处理它，然后在需要的时候再去处理它们。</p>
<p><img src="/2023/03/21/Kafka/Kafka%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-%E5%BC%82%E6%AD%A5.png" alt="Kafka消息队列-异步.png"></p>
</li>
</ul>
<h4 id="消息队列的两种模式"><a href="#消息队列的两种模式" class="headerlink" title="消息队列的两种模式"></a>消息队列的两种模式</h4><h5 id="点对点模式"><a href="#点对点模式" class="headerlink" title="点对点模式"></a>点对点模式</h5><ul>
<li><p>消费者主动拉取数据，消息收到后清除消息</p>
<p><img src="/2023/03/21/Kafka/Kakfa%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-%E7%82%B9%E5%AF%B9%E7%82%B9%E6%A8%A1%E5%BC%8F.png" alt="Kakfa消息队列-点对点模式.png"></p>
</li>
</ul>
<h5 id="发布-x2F-订阅模式"><a href="#发布-x2F-订阅模式" class="headerlink" title="发布 &#x2F; 订阅模式"></a>发布 &#x2F; 订阅模式</h5><ul>
<li><p>可以有多个topic主题</p>
</li>
<li><p>消费者消费数据之后，不删除数据</p>
</li>
<li><p>每个消费者相互独立，都可以消费到数据</p>
<p><img src="/2023/03/21/Kafka/Kafka%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85%E6%A8%A1%E5%BC%8F.png" alt="Kafka消息队列-发布订阅模式.png"></p>
</li>
</ul>
<h3 id="Kafka-基础架构"><a href="#Kafka-基础架构" class="headerlink" title="Kafka 基础架构"></a>Kafka 基础架构</h3><ol>
<li>为方便扩展，并提高吞吐量，一个 topic 分为多个 partition</li>
<li>配合分区的设计，提出消费者组的概念，组内每个消费者并行消费</li>
<li>为提高可用性，为每个 partition 增加若干副本，类似 NameNode HA</li>
<li>Zookeeper 中记录谁是 Leader，Kafka2.8.0 以后也可以配置不采用 Zookeeper</li>
</ol>
<p><img src="/2023/03/21/Kafka/Kafka%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84.png" alt="Kafka基本架构.png"></p>
<blockquote>
<p><strong>各个组件说明：</strong></p>
<ol>
<li><p><strong>Producer：消息生产者，就是向 Kafka broker 发消息的客户端</strong></p>
</li>
<li><p><strong>Consumer：消息消费者，向 Kafka broker 取消息的客户端</strong></p>
</li>
<li><p><strong>Consumer Group（CG）：消费者组，由多个 consumer 组成。消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。</strong></p>
</li>
<li><p><strong>Broker：一台 Kafka 服务器就是一个 broker。一个集群由多个 broker 组成。一个 broker 可以容纳多个 topic</strong></p>
</li>
<li><p><strong>Topic：可以理解为一个队列，生产者和消费者面向的都是一个 topic</strong></p>
</li>
<li><p><strong>Partition：为了实现扩展性，一个非常大的 topic 可以分布到多个 broker（即服 务器）上，一个 topic 可以分为多个 partition，每个 partition 是一个有序的队列。</strong></p>
</li>
<li><p><strong>Replica：副本，一个 topic 的每个分区都有若干个副本，一个 Leader 和若干个 Follower。</strong></p>
</li>
<li><p><strong>Leader：每个分区多个副本的 “主”，生产者发送数据的对象，以及消费者消费数据的对象都是 Leader。</strong></p>
</li>
<li><p><strong>Follower：每个分区多个副本中的 “从”，实时从 Leader 中同步数据，保持和 Leader 数据的同步。Leader 发生故障时，某个 Follower 会成为新的 Leader。</strong></p>
</li>
</ol>
</blockquote>
<h2 id="Kafka-入门示例"><a href="#Kafka-入门示例" class="headerlink" title="Kafka 入门示例"></a>Kafka 入门示例</h2><p>Kafka 下载地址：<a target="_blank" rel="noopener" href="https://kafka.apache.org/downloads">https://kafka.apache.org/downloads</a></p>
<p>以 <code>kafka_2.12-3.0.0.tgz</code> 为例，Kafka 由 Scala 和 Java 两种语言编写，Producer 和 Consumer 由 Java 编写，Broker 由 Scala 编写。</p>
<h3 id="预先准备"><a href="#预先准备" class="headerlink" title="预先准备"></a>预先准备</h3><h4 id="配置-Java-环境"><a href="#配置-Java-环境" class="headerlink" title="配置 Java 环境"></a>配置 Java 环境</h4><ul>
<li><p>卸载自带的 OpenJDK（可选）</p>
</li>
<li><p>配置 Java 环境变量</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">java</span></span><br><span class="line">export JAVA_HOME=/opt/java/jdk1.8.0_131</span><br><span class="line">export JRE_HOME=/opt/java/jdk1.8.0_131/jre</span><br><span class="line">export CLASSPATH=.:%JAVA_HOME%/lib:%JAVA_HOME%/lib</span><br><span class="line">export PATH=$JAVA_HOME/bin:$PATH</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="配置集群免密登录"><a href="#配置集群免密登录" class="headerlink" title="配置集群免密登录"></a>配置集群免密登录</h4><ul>
<li><p>配置集群 ip 映射</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost kafka3.x]# cat /etc/hosts</span><br><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line">192.168.100.100 192.168.100.100</span><br><span class="line">192.168.100.110 192.168.100.110</span><br><span class="line">192.168.100.120 192.168.100.120</span><br></pre></td></tr></table></figure>
</li>
<li><p>生成秘钥</p>
<p>会在 ~ 目录下生成 .ssh 目录</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# ssh-keygen -t rsa</span><br></pre></td></tr></table></figure>
</li>
<li><p>分发秘钥</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# ssh-copy-id 192.168.100.100</span><br><span class="line">[root@localhost ~]# ssh-copy-id 192.168.100.110</span><br><span class="line">[root@localhost ~]# ssh-copy-id 192.168.100.120</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="分发脚本-xsync-sh"><a href="#分发脚本-xsync-sh" class="headerlink" title="分发脚本 xsync.sh"></a>分发脚本 xsync.sh</h4><blockquote>
<ul>
<li>创建脚本 xsync.sh，传入要传输的目录名</li>
<li>shell 脚本要求具有执行权限：chmod +x xsync.sh</li>
<li>shell 脚本保存或者软链接在 &#x2F;usr&#x2F;bin 这样的目录下，以使命令全局有效</li>
</ul>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">判断参数个数</span></span><br><span class="line">if [ $# -lt 1 ]</span><br><span class="line">then</span><br><span class="line">        echo &quot;Not  Enough Arguments&quot;</span><br><span class="line">        exit</span><br><span class="line">fi</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">遍历所有主机</span></span><br><span class="line">for host in 192.168.100.100 192.168.100.110 192.168.100.120</span><br><span class="line">do</span><br><span class="line">        echo ========$host========</span><br><span class="line">        # 遍历所有目录</span><br><span class="line">        for file in $@</span><br><span class="line">        do</span><br><span class="line">                if [ -e $file ]</span><br><span class="line">                then</span><br><span class="line">                        # 如果文件存在，获取父目录，</span><br><span class="line">                        # pwd -P：如果目录是链接时，显示出实际路径，而非使用连接（link）路径。pwd防止传入相对路径</span><br><span class="line">                        # cd -P:如果目录是链接时，切换到实际路径的目录。</span><br><span class="line">                        pdir=$(cd -P $(dirname $file);pwd)</span><br><span class="line">                        # 获取文件名称</span><br><span class="line">                        filename=$(basename $file)</span><br><span class="line">                        ssh $host &quot;mkdir -p $pdir&quot;</span><br><span class="line">                        rsync -av $pdir/$filename $host:$pdir</span><br><span class="line">                else</span><br><span class="line">                        echo $file not exist!</span><br><span class="line">                fi</span><br><span class="line">        done</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<h4 id="查看-Java-进程-jspall-sh"><a href="#查看-Java-进程-jspall-sh" class="headerlink" title="查看 Java 进程  jspall.sh"></a>查看 Java 进程  jspall.sh</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">for host in 192.168.100.100 192.168.100.110 192.168.100.120</span><br><span class="line">do</span><br><span class="line"> echo ========$host========</span><br><span class="line"> ssh $host  &quot;source /etc/profile &amp;&amp; jps | grep -v jps &quot;</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<h3 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h3><p>以 <code>apache-zookeeper-3.5.7-bin.tar.gz</code> 、<code>kafka_2.12-3.0.0.tgz</code> 为例。</p>
<h4 id="安装-Zookeeper"><a href="#安装-Zookeeper" class="headerlink" title="安装 Zookeeper"></a>安装 Zookeeper</h4><h5 id="单机版"><a href="#单机版" class="headerlink" title="单机版"></a>单机版</h5><p>Zookeeper 地址：<a target="_blank" rel="noopener" href="https://zookeeper.apache.org/releases.html">https://zookeeper.apache.org/releases.html</a></p>
<p>Zookeeper  版本：apache-zookeeper-3.5.7-bin.tar.gz，解压至 &#x2F;opt&#x2F;zookeeper&#x2F;</p>
<p>安装准备：安装 JDK，解压至 &#x2F;opt&#x2F;zookeeper&#x2F;，重命名文件夹名称</p>
<p>配置 Java 环境变量：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">java</span></span><br><span class="line">export JAVA_HOME=/opt/java/jdk1.8.0_131</span><br><span class="line">export JRE_HOME=/opt/java/jdk1.8.0_131/jre</span><br><span class="line">export CLASSPATH=.:%JAVA_HOME%/lib:%JAVA_HOME%/lib</span><br><span class="line">export PATH=$JAVA_HOME/bin:$PATH</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">zookeeper</span></span><br><span class="line">export ZOOKEEPER_HOME=/opt/zookeeper/zookeeper-3.5.7</span><br><span class="line">export PATH=$ZOOKEEPER_HOME/bin:$PATH</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>刷新环境变量配置：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">或者修改 ~/.bash_profile， <span class="built_in">source</span> ~/.bash_profile</span></span><br></pre></td></tr></table></figure>

<p>解压 Zookeeper：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@root zookeeper]# ll zookeeper-3.5.7/</span><br><span class="line">总用量 32</span><br><span class="line">drwxr-xr-x. 2  502 games   232 2月  10 2020 bin</span><br><span class="line">drwxr-xr-x. 2  502 games    77 2月   7 2020 conf</span><br><span class="line">drwxr-xr-x. 5  502 games  4096 2月  10 2020 docs</span><br><span class="line">drwxr-xr-x. 2 root root   4096 9月  27 18:40 lib</span><br><span class="line">-rw-r--r--. 1  502 games 11358 9月  13 2018 LICENSE.txt</span><br><span class="line">-rw-r--r--. 1  502 games   432 2月  10 2020 NOTICE.txt</span><br><span class="line">-rw-r--r--. 1  502 games  1560 2月   7 2020 README.md</span><br><span class="line">-rw-r--r--. 1  502 games  1347 2月   7 2020 README_packaging.txt</span><br></pre></td></tr></table></figure>

<p>修改配置：将 conf 路径下 zoo_sample.cfg 修改为 zoo.cfg，并修改文件中 dataDir 的路径，一般设置为安装目录下的 zkData（mkdir  zkData）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@root conf]# mv zoo_sample.cfg zoo.cfg</span><br><span class="line">[root@root conf]# vim zoo.cfg</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">The number of milliseconds of each tick</span></span><br><span class="line">tickTime=2000</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">The number of ticks that the initial</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">synchronization phase can take</span></span><br><span class="line">initLimit=10</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">The number of ticks that can pass between</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">sending a request and getting an acknowledgement</span></span><br><span class="line">syncLimit=5</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">the directory <span class="built_in">where</span> the snapshot is stored.</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="keyword">do</span> not use /tmp <span class="keyword">for</span> storage, /tmp here is just</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">example sakes.</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">dataDir=/tmp/zookeeper</span></span><br><span class="line">dataDir=/opt/zookeeper/zookeeper-3.5.7/zkData</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">the port at <span class="built_in">which</span> the clients will connect</span></span><br><span class="line">clientPort=2181</span><br></pre></td></tr></table></figure>

<p>操作 Zookeeper：</p>
<p>​		启动 Zookeeper：zkServer.sh  start</p>
<p>​		查看进程是否启动：jps </p>
<p>​		查看状态：zkServer.sh  status</p>
<p>​		启动客户端：zkCli.sh</p>
<p>​		退出客户端：quit</p>
<p>​		停止 Zookeeper：zkServer.sh  stop</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@root zookeeper-3.5.7]# cd bin</span><br><span class="line">[root@root bin]# zkServer.sh start</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/zookeeper/zookeeper-3.5.7/bin/../conf/zoo.cfg</span><br><span class="line">Starting zookeeper ... STARTED</span><br><span class="line">[root@root bin]# jps</span><br><span class="line">5191 Jps</span><br><span class="line">5160 QuorumPeerMain</span><br><span class="line">[root@root bin]# zkServer.sh status</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/zookeeper/zookeeper-3.5.7/bin/../conf/zoo.cfg</span><br><span class="line">Client port found: 2181. Client address: localhost.</span><br><span class="line">Mode: standalone</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">退出</span></span><br><span class="line">[root@root bin]# zkServer.sh stop</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@root bin]# zkCli.sh</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">.....</span></span><br><span class="line">2022-09-27 19:09:18,427 [myid:localhost:2181] - INFO  [main-SendThread(localhost:2181):ClientCnxn$SendThread@1394] - Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10000be49f20002, negotiated timeout = 30000</span><br><span class="line"></span><br><span class="line">WATCHER::</span><br><span class="line"></span><br><span class="line">WatchedEvent state:SyncConnected type:None path:null</span><br><span class="line">[zk: localhost:2181(CONNECTED) 0] ls /</span><br><span class="line">[zookeeper]</span><br></pre></td></tr></table></figure>

<p>配置参数说明：</p>
<p>配置文件 zoo.cfg 中参数含义：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">The number of milliseconds of each tick</span></span><br><span class="line">tickTime=2000</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">The number of ticks that the initial</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">synchronization phase can take</span></span><br><span class="line">initLimit=10</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">The number of ticks that can pass between</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">sending a request and getting an acknowledgement</span></span><br><span class="line">syncLimit=5</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">the directory <span class="built_in">where</span> the snapshot is stored.</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="keyword">do</span> not use /tmp <span class="keyword">for</span> storage, /tmp here is just</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">example sakes.</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">dataDir=/tmp/zookeeper</span></span><br><span class="line">dataDir=/opt/zookeeper/zookeeper-3.5.7/zkData</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">the port at <span class="built_in">which</span> the clients will connect</span></span><br><span class="line">clientPort=2181</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">the maximum number of client connections.</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">increase this <span class="keyword">if</span> you need to handle more clients</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">maxClientCnxns=60</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment"># Be sure to read the maintenance section of the</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">administrator guide before turning on autopurge.</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment"># http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"><span class="comment"># The number of snapshots to retain in dataDir</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">autopurge.snapRetainCount=3</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Purge task interval <span class="keyword">in</span> hours</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Set to <span class="string">&quot;0&quot;</span> to <span class="built_in">disable</span> auto purge feature</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">autopurge.purgeInterval=1</span></span><br></pre></td></tr></table></figure>

<p>tickTime &#x3D; 2000：通信心跳时间，Zookeeper服务器与客户端心跳时间，单位毫秒</p>
<p>initLimit &#x3D; 10：LF 初始通信时限，Leader和Follower初始连接时能容忍的最多心跳数<strong>（tickTime的数量）</strong></p>
<p>syncLimit &#x3D; 5：LF 同步通信时限，Leader和Follower之间通信时间如果超过syncLimit * tickTime，Leader认为Follwer死 						掉，从服务器列表中删除Follwer。</p>
<p>dataDir：保存Zookeeper中的数据，默认的tmp目录，容易被Linux系统定期删除，所以一般不用默认的tmp目录。</p>
<p>clientPort &#x3D; 2181：客户端连接端口，通常不做修改。</p>
<p>maxClientCnxns&#x3D;60：客户端最大连接数量</p>
<p>参数说明：<a target="_blank" rel="noopener" href="https://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance">https://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance</a></p>
<h5 id="集群版"><a href="#集群版" class="headerlink" title="集群版"></a>集群版</h5><ol>
<li><p>在三台机器上安装 Zookeeper</p>
</li>
<li><p>配置服务器编号：<strong>在安装目录配置 zkData，在 zkData 下创建 myid 文件，在文件中添加与 server 对应的编号</strong></p>
</li>
<li><p>分发 zookeeper 至其他机器</p>
</li>
<li><p>配置 zoo.cfg文件，增加如下配置：</p>
<p>server.0&#x3D;192.168.100.100:2888:3888</p>
<p>server.1&#x3D;192.168.100.110:2888:3888</p>
<p>server.2&#x3D;192.168.100.120:2888:3888</p>
<p>配置参数说明：</p>
<p>server.A&#x3D;B:C:D</p>
<p>A 表示集群模式下，配置一个文件 myid 中的机器编号，Zookeeper 启动时读取此文件，拿到里面的数据与 zoo.cfg 里面的配置信息比较从而判断到底是哪个 server。</p>
<p>B 是服务器的地址</p>
<p>C 是这个服务器 Follower 与集群中的 Leader 服务器交换信息的端口</p>
<p>D 是用来执行选举时服务器相互通信的端口。</p>
</li>
<li><p>通过 xsync.sh 分发配置文件，并修改文件 myid  中的编号</p>
</li>
<li><p>创建 Zookeeper 集群启动脚本 <code>zk.sh</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">case $1 in</span><br><span class="line">&quot;start&quot;)&#123;</span><br><span class="line">	for host in 192.168.100.100 192.168.100.110 192.168.100.120</span><br><span class="line">	do</span><br><span class="line">		echo &quot;========zookeeper $host start========&quot;</span><br><span class="line">		ssh $host &quot;/opt/zookeeper/zookeeper-3.5.7/bin/zkServer.sh start&quot;</span><br><span class="line">	done</span><br><span class="line">&#125;</span><br><span class="line">;;</span><br><span class="line">&quot;status&quot;)&#123;</span><br><span class="line">	for host in 192.168.100.100 192.168.100.110 192.168.100.120</span><br><span class="line">	do</span><br><span class="line">		echo &quot;========zookeeper $host status========&quot;</span><br><span class="line">		ssh $host &quot;/opt/zookeeper/zookeeper-3.5.7/bin/zkServer.sh status&quot;</span><br><span class="line">	done</span><br><span class="line">&#125;</span><br><span class="line">;;</span><br><span class="line">&quot;stop&quot;)&#123;</span><br><span class="line">	for host in 192.168.100.100 192.168.100.110 192.168.100.120</span><br><span class="line">	do</span><br><span class="line">		echo &quot;========zookeeper $host stop========&quot;</span><br><span class="line">		ssh $host &quot;/opt/zookeeper/zookeeper-3.5.7/bin/zkServer.sh stop&quot;</span><br><span class="line">	done</span><br><span class="line">&#125;</span><br><span class="line">;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure>
</li>
<li><p>启动 Zookeeper 集群：</p>
<p>通过 <code>zk.sh</code> 启动集群：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost shell]# zk.sh start</span><br><span class="line">========zookeeper 192.168.100.100 start========</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/zookeeper/zookeeper-3.5.7/bin/../conf/zoo.cfg</span><br><span class="line">Starting zookeeper ... STARTED</span><br><span class="line">========zookeeper 192.168.100.110 start========</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/zookeeper/zookeeper-3.5.7/bin/../conf/zoo.cfg</span><br><span class="line">Starting zookeeper ... STARTED</span><br><span class="line">========zookeeper 192.168.100.120 start========</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/zookeeper/zookeeper-3.5.7/bin/../conf/zoo.cfg</span><br><span class="line">Starting zookeeper ... STARTED</span><br><span class="line">[root@localhost shell]# zk.sh status</span><br><span class="line">========zookeeper 192.168.100.100 status========</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/zookeeper/zookeeper-3.5.7/bin/../conf/zoo.cfg</span><br><span class="line">Client port found: 2181. Client address: localhost.</span><br><span class="line">Mode: follower</span><br><span class="line">========zookeeper 192.168.100.110 status========</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/zookeeper/zookeeper-3.5.7/bin/../conf/zoo.cfg</span><br><span class="line">Client port found: 2181. Client address: localhost.</span><br><span class="line">Mode: leader</span><br><span class="line">========zookeeper 192.168.100.120 status========</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/zookeeper/zookeeper-3.5.7/bin/../conf/zoo.cfg</span><br><span class="line">Client port found: 2181. Client address: localhost.</span><br><span class="line">Mode: follower</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>报错解决：</strong></p>
<ul>
<li><p>报错一：</p>
<figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">注意报错：</span><br><span class="line"></span><br><span class="line">​```shell</span><br><span class="line"><span class="params">#</span> 如果报错：Error: JAVA<span class="built_in">_</span>HOME is not set and java could not be found in PATH.</span><br><span class="line"><span class="params">#</span> 单机启动没有问题，但集群启动报错</span><br><span class="line"><span class="params">#</span> 解决：在 zookeeper/bin/zkEnv.sh 头部手动添加 JAVA<span class="built_in">_</span>HOME=/opt/java/jdk1.8.0<span class="built_in">_</span>131</span><br><span class="line"><span class="params">#</span> 修改完成后，重新分发</span><br><span class="line">​```</span><br><span class="line"></span><br><span class="line">​```shell</span><br><span class="line">[root@root zookeeper-3.5.7]<span class="params">#</span> zkServer.sh status</span><br><span class="line">ZooKeeper JMX enabled by default</span><br></pre></td></tr></table></figure>
</li>
<li><p>报错二：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Using config: /opt/zookeeper/zookeeper-3.5.7/bin/../conf/zoo.cfg</span><br><span class="line">Client port found: 2181. Client address: localhost.</span><br><span class="line">Error contacting service. It is probably not running.</span><br><span class="line"></span><br><span class="line">原因：</span><br><span class="line">  1. Leader 和 Follower 未选出，或无法连接</span><br><span class="line">  2. 只启动不到一半数量的集群，或者防火墙未关闭</span><br><span class="line">  </span><br><span class="line">     关闭防火墙：</span><br><span class="line">     CentOS7：</span><br><span class="line">	</span><br><span class="line">     systemctl status firewalld.service</span><br><span class="line">     systemctl stop firewalld.service	#关闭</span><br><span class="line">     systemctl disabled firewalld.service	# 禁用</span><br><span class="line"></span><br><span class="line">     CentOS6：</span><br><span class="line">     service iptables status</span><br><span class="line">     service iptables stop</span><br><span class="line">     chkconfig iptables off</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ol>
<h4 id="安装-Kafka"><a href="#安装-Kafka" class="headerlink" title="安装 Kafka"></a>安装 Kafka</h4><p>官方下载地址：<a target="_blank" rel="noopener" href="http://kafka.apache.org/downloads.html">http://kafka.apache.org/downloads.html</a></p>
<ul>
<li><p>集群主机：<code>192.168.100.100 、192.168.100.110 、192.168.100.120</code></p>
</li>
<li><p>上传并解压到 &#x2F;opt&#x2F;kafka&#x2F;kafka3.x</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost kafka3.x]# ll</span><br><span class="line">总用量 68</span><br><span class="line">drwxr-xr-x. 3 root root  4096 3月  21 12:55 bin</span><br><span class="line">drwxr-xr-x. 3 root root  4096 3月  21 11:44 config</span><br><span class="line">drwxr-xr-x. 2 root root   187 3月  22 00:33 datas</span><br><span class="line">drwxr-xr-x. 2 root root  8192 3月  21 09:59 libs</span><br><span class="line">-rw-r--r--. 1 root root 14521 9月   9 2021 LICENSE</span><br><span class="line">drwxr-xr-x. 2 root root   262 9月   9 2021 licenses</span><br><span class="line">drwxr-xr-x. 2 root root  4096 3月  22 00:00 logs</span><br><span class="line">-rw-r--r--. 1 root root 28184 9月   9 2021 NOTICE</span><br><span class="line">drwxr-xr-x. 2 root root    44 9月   9 2021 site-docs</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改配置文件：config&#x2F;server.properties</p>
<p>主要修改：<code>broker.id</code> 、 <code>log.dirs</code> 、<code>zookeeper.connect</code></p>
<ul>
<li>broker.id：broker 的全局唯一编号，不能重复，只能是数字</li>
<li>log.dirs：kafka 运行日志（数据）存放的路径，路径不需要提前创建，kafka 自动创建，可以配置多个磁盘路径，路径与路径之间可以用 “，” 分隔</li>
<li>zookeeper.connect：配置连接 Zookeeper 集群地址（在 zk 根目录下创建&#x2F;kafka，方便管理）</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">broker 的全局唯一编号，不能重复，只能是数字</span></span><br><span class="line">broker.id=0</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">处理网络请求的线程数量</span></span><br><span class="line">num.network.threads=3</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">用来处理磁盘 IO 的线程数量</span></span><br><span class="line">num.io.threads=8</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">发送套接字的缓冲区大小</span></span><br><span class="line">socket.send.buffer.bytes=102400</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">接收套接字的缓冲区大小</span></span><br><span class="line">socket.receive.buffer.bytes=102400</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">请求套接字的缓冲区大小</span></span><br><span class="line">socket.request.max.bytes=104857600</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">kafka 运行日志(数据)存放的路径，路径不需要提前创建，kafka 自动创建，可以</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">配置多个磁盘路径，路径与路径之间可以用<span class="string">&quot;，&quot;</span>分隔</span></span><br><span class="line">log.dirs=/opt/kafka/kafka3.x/datas</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">topic 在当前 broker 上的分区个数</span></span><br><span class="line">num.partitions=1</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">用来恢复和清理 data 下数据的线程数量</span></span><br><span class="line">num.recovery.threads.per.data.dir=1</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">每个 topic 创建时的副本数，默认时 1 个副本</span></span><br><span class="line">offsets.topic.replication.factor=1</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">segment 文件保留的最长时间，超时将被删除</span></span><br><span class="line">log.retention.hours=168</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">每个 segment 文件的大小，默认最大 1G</span></span><br><span class="line">log.segment.bytes=1073741824</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">检查过期数据的时间，默认 5 分钟检查一次是否数据过期</span></span><br><span class="line">log.retention.check.interval.ms=300000</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">配置连接 Zookeeper 集群地址（在 zk 根目录下创建/kafka，方便管理）</span></span><br><span class="line">zookeeper.connect=hadoop102:2181,hadoop103:2181,hadoop104:2181/kafka</span><br></pre></td></tr></table></figure>
</li>
<li><p>分发 Kafka 目录并修改 broker.id</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost kafka]#  xsync kafka3.x/</span><br></pre></td></tr></table></figure>

<p>修改 192.168.100.110 、192.168.100.120 的 <code>kafka3.x/config/server.propertis</code> 中的 broker.id</p>
<p> 192.168.100.110 ：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">############################ Server Basics #############################</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">The <span class="built_in">id</span> of the broker. This must be <span class="built_in">set</span> to a unique <span class="built_in">integer</span> <span class="keyword">for</span> each broker.</span></span><br><span class="line">broker.id=1</span><br></pre></td></tr></table></figure>

<p> 192.168.100.120：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">############################ Server Basics #############################</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">The <span class="built_in">id</span> of the broker. This must be <span class="built_in">set</span> to a unique <span class="built_in">integer</span> <span class="keyword">for</span> each broker.</span></span><br><span class="line">broker.id=2</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置 Kafka 环境变量并刷新</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">java</span></span><br><span class="line">export JAVA_HOME=/opt/java/jdk1.8.0_131</span><br><span class="line">export JRE_HOME=/opt/java/jdk1.8.0_131/jre</span><br><span class="line">export CLASSPATH=.:%JAVA_HOME%/lib:%JAVA_HOME%/lib</span><br><span class="line">export PATH=$JAVA_HOME/bin:$PATH</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">zookeeper</span></span><br><span class="line">export ZOOKEEPER_HOME=/opt/zookeeper/zookeeper-3.5.7</span><br><span class="line">export PATH=$ZOOKEEPER_HOME/bin:$PATH</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">KAFKA_HOME</span></span><br><span class="line">export KAFKA_HOME=/opt/kafka/kafka3.x</span><br><span class="line">export PATH=$PATH:$KAFKA_HOME/bin</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>刷新环境变量：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost kafka3.x]#  source /etc/profile</span><br></pre></td></tr></table></figure>
</li>
<li><p>分发环境变量并刷新</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost kafka]#  xsync /etc/profile</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> 192.168.100.110、192.168.100.120</span></span><br><span class="line">[root@localhost kafka]#  source /etc/profile</span><br></pre></td></tr></table></figure>
</li>
<li><p>启动集群</p>
<ul>
<li><p>第一步：启动 Zookeeper 集群</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost kafka3.x]#  zk.sh start</span><br></pre></td></tr></table></figure>
</li>
<li><p>第二步：依次启动 <code>192.168.100.100 、192.168.100.110 、192.168.100.120</code> 的 Kafka</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost kafka3.x]# /opt/kafka/kafka3.x/bin/kafka-server-start.sh -daemon /opt/kafka/kafka3.x/config/server.properties</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看进程</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost kafka3.x]# jpsall.sh</span><br><span class="line">========192.168.100.100========</span><br><span class="line">4577 QuorumPeerMain</span><br><span class="line">4978 Kafka</span><br><span class="line">5093 Jps</span><br><span class="line">========192.168.100.110========</span><br><span class="line">11639 Kafka</span><br><span class="line">11738 Jps</span><br><span class="line">11151 QuorumPeerMain</span><br><span class="line">========192.168.100.120========</span><br><span class="line">11169 QuorumPeerMain</span><br><span class="line">11735 Jps</span><br><span class="line">11644 Kafka</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>停止集群，依次停止 <code>192.168.100.100 、192.168.100.110 、192.168.100.120</code> 的 Kafka</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost kafka3.x]# /opt/kafka/kafka3.x/bin/kafka-server-stop.sh</span><br></pre></td></tr></table></figure>

<p>注意：<strong>停止 Kafka 集群时，需要一定时间，一定要等 Kafka 所有节点进程全部停止后再停止 Zookeeper 集群</strong>。因为 Zookeeper 集群当中记录着 Kafka 集群相关信息，Zookeeper 集群一旦先停止， Kafka 集群就没有办法再获取停止进程的信息，只能手动杀死 Kafka 进程。</p>
</li>
<li><p>集群启停脚本 <code>kf.sh</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">! /bin/bash</span></span><br><span class="line">case $1 in</span><br><span class="line">&quot;start&quot;)&#123;</span><br><span class="line">        for i in 192.168.100.100 192.168.100.110 192.168.100.120</span><br><span class="line">                do</span><br><span class="line">                        echo &quot; --------Start $i Kafka-------&quot;</span><br><span class="line">                        ssh $i &quot;/opt/kafka/kafka3.x/bin/kafka-server-start.sh -daemon /opt/kafka/kafka3.x/config/server.properties&quot;</span><br><span class="line">                done</span><br><span class="line">&#125;;;</span><br><span class="line">&quot;stop&quot;)&#123;</span><br><span class="line">        for i in 192.168.100.100 192.168.100.110 192.168.100.120</span><br><span class="line">                do</span><br><span class="line">                        echo &quot; --------Stop $i Kafka-------&quot;</span><br><span class="line">                        ssh $i &quot;/opt/kafka/kafka3.x/bin/kafka-server-stop.sh &quot;</span><br><span class="line">                done</span><br><span class="line">&#125;;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure>

<p><strong>注意：</strong>这里有个问题，单机执行 Kafka 启动命令可以运行，但是使用 kf.sh 脚本执行不会启动 Kafka，且会报错：nohup: 无法运行命令”java”: 没有那个文件或目</p>
<p>录，需要修改 shell 脚本：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">! /bin/bash</span></span><br><span class="line">case $1 in</span><br><span class="line">&quot;start&quot;)&#123;</span><br><span class="line">        for i in 192.168.100.100 192.168.100.110 192.168.100.120</span><br><span class="line">                do</span><br><span class="line">                        echo &quot; --------Start $i Kafka-------&quot;</span><br><span class="line">                        ssh $i &quot;source /etc/profile;nohup /opt/kafka/kafka3.x/bin/kafka-server-start.sh -daemon /opt/kafka/kafka3.x/config/server.properties&quot;</span><br><span class="line">                done</span><br><span class="line">&#125;;;</span><br><span class="line">&quot;stop&quot;)&#123;</span><br><span class="line">        for i in 192.168.100.100 192.168.100.110 192.168.100.120</span><br><span class="line">                do</span><br><span class="line">                        echo &quot; --------Stop $i Kafka-------&quot;</span><br><span class="line">                        ssh $i &quot;source /etc/profile;nohup /opt/kafka/kafka3.x/bin/kafka-server-stop.sh &quot;</span><br><span class="line">                done</span><br><span class="line">&#125;;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure>

<p>设置权限并拷贝到 &#x2F;usr&#x2F;bin 目录下：（或建立软链接）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost shell]# chmod +x kf.sh</span><br><span class="line">[root@localhost shell]# cp kf.sh /usr/bin/</span><br></pre></td></tr></table></figure>
</li>
<li><p>注意事项</p>
<p>启动 Kafka 几秒后进程退出</p>
<p><strong>解决方案：查看启动日志</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost kafka3.x]# cat log/server.log</span><br><span class="line">[2023-01-12 23:22:11,589] INFO Cluster ID = Zc7nlyfTQ5qPbhY2d8I_3A (kafka.server.KafkaServer)</span><br><span class="line">[2023-01-12 23:22:11,598] ERROR Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)</span><br><span class="line">kafka.common.InconsistentClusterIdException: The Cluster ID 1_3tWXR8Q16qq7H2vwhIng doesn&#x27;t match s tored clusterId Some(ivQZIX9gTB-dj05be_i_-w) in meta.properties. The broker is trying to join the wrong cluster. Configured zookeeper.connect may be wrong.</span><br><span class="line">    at kafka.server.KafkaServer.startup(KafkaServer.scala:228)</span><br><span class="line">    at kafka.Kafka$.main(Kafka.scala:109)</span><br><span class="line">    at kafka.Kafka.main(Kafka.scala)</span><br></pre></td></tr></table></figure>

<p>第一步：<strong>确定内存够用，可以修改，Kafka 默认 1G</strong></p>
<p>第二步：<strong>meta.properties 和 cluster_id 不一致</strong>，要么删除目录 <code>log.dirs=/opt/kafka/kafka3.x/datas</code>后重新启动（推荐），要么手动修改（不推荐）</p>
</li>
<li><p>启动报错：查看 logs&#x2F;server.log 启动日志</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists</span><br><span class="line">        at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)</span><br><span class="line">        at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1904)</span><br><span class="line">        at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1842)</span><br><span class="line">        at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1809)</span><br><span class="line">        at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:96)</span><br><span class="line">        at kafka.server.KafkaServer.startup(KafkaServer.scala:319)</span><br><span class="line">        at kafka.Kafka$.main(Kafka.scala:109)</span><br><span class="line">        at kafka.Kafka.main(Kafka.scala)</span><br></pre></td></tr></table></figure>

<p>原因：之前 Kafka 在运行时没有正常关闭，导致一些临时节点没有被删除。要解决这个问题，可以尝试删除旧的临时节点并重新启动 Kafka</p>
</li>
</ul>
<h3 id="命令行操作"><a href="#命令行操作" class="headerlink" title="命令行操作"></a>命令行操作</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost kafka3.x]# cd bin &amp;&amp; ls</span><br><span class="line">connect-distributed.sh        kafka-dump-log.sh              kafka-storage.sh</span><br><span class="line">connect-mirror-maker.sh       kafka-features.sh              kafka-streams-application-reset.sh</span><br><span class="line">connect-standalone.sh         kafka-get-offsets.sh           kafka-topics.sh</span><br><span class="line">kafka-acls.sh                 kafka-leader-election.sh       kafka-transactions.sh</span><br><span class="line">kafka-broker-api-versions.sh  kafka-log-dirs.sh              kafka-verifiable-consumer.sh</span><br><span class="line">kafka-cluster.sh              kafka-metadata-shell.sh        kafka-verifiable-producer.sh</span><br><span class="line">kafka-configs.sh              kafka-mirror-maker.sh          trogdor.sh</span><br><span class="line">kafka-console-consumer.sh     kafka-producer-perf-test.sh    windows</span><br><span class="line">kafka-console-producer.sh     kafka-reassign-partitions.sh   zookeeper-security-migration.sh</span><br><span class="line">kafka-consumer-groups.sh      kafka-replica-verification.sh  zookeeper-server-start.sh</span><br><span class="line">kafka-consumer-perf-test.sh   kafka-run-class.sh             zookeeper-server-stop.sh</span><br><span class="line">kafka-delegation-tokens.sh    kafka-server-start.sh          zookeeper-shell.sh</span><br><span class="line">kafka-delete-records.sh       kafka-server-stop.sh</span><br><span class="line">[root@localhost kafka3.x]#</span><br></pre></td></tr></table></figure>

<ul>
<li>生产者：kafka-console-producer.sh </li>
<li>消费者：kafka-console-consumer.sh </li>
<li>主题（集群）：kafka-topics.sh</li>
</ul>
<h4 id="主题相关命令"><a href="#主题相关命令" class="headerlink" title="主题相关命令"></a>主题相关命令</h4><p>查看主题操作的相关命令参数：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">主题命令</span></span><br><span class="line">[root@localhost kafka3.x]# bin/kafka-topics.sh</span><br></pre></td></tr></table></figure>

<p>常用参数：</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>–bootstrap-server &lt;String: server to connect to&gt;</td>
<td>连接的 Kafka Broker 主机名称和端口号</td>
</tr>
<tr>
<td>–topic &lt;String: topic&gt;</td>
<td>topic 的名称</td>
</tr>
<tr>
<td>–create</td>
<td>创建主题</td>
</tr>
<tr>
<td>–delete</td>
<td>删除主题</td>
</tr>
<tr>
<td>–alter</td>
<td>修改主题</td>
</tr>
<tr>
<td>–list</td>
<td>查看所有主题</td>
</tr>
<tr>
<td>–describe</td>
<td>查看主题详细描述信息</td>
</tr>
<tr>
<td>–partitions &lt;Integer: # of partitions&gt;</td>
<td>设置分区数</td>
</tr>
<tr>
<td>–replication-factor</td>
<td>设置分区副本</td>
</tr>
<tr>
<td>–config &lt;String: name&#x3D;value&gt;</td>
<td>更新系统默认的配置</td>
</tr>
</tbody></table>
<p>示例：</p>
<ul>
<li><p>查看所有主题</p>
<p>多个 broker 以逗号隔开</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost kafka3.x]# bin/kafka-topics.sh --bootstrap-server 192.168.100.100:9092 --list</span><br><span class="line"></span><br><span class="line">[root@localhost kafka3.x]# bin/kafka-topics.sh --bootstrap-server 192.168.100.100:9092,192.168.100.110:9092 --list</span><br><span class="line"></span><br><span class="line">[root@localhost kafka3.x]# bin/kafka-topics.sh --bootstrap-server 192.168.100.100:9092,192.168.100.110:9092,192.168.100.120:9092 --list</span><br></pre></td></tr></table></figure>
</li>
<li><p>创建主题 first</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost kafka3.x]# bin/kafka-topics.sh --bootstrap-server 192.168.100.100:9092 --create --partitions 1 --replication-factor 3 --topic first</span><br><span class="line">Created topic first.</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看主题详情</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">    [root@localhost kafka3.x]# bin/kafka-topics.sh --bootstrap-server 192.168.100.100:9092 --describe --topic first</span><br><span class="line">Topic: first    TopicId: RO0D3TvwR8yI3TX50bRZKQ PartitionCount: 1       ReplicationFactor: 3    Configs: segment.bytes=1073741824</span><br><span class="line">        Topic: first    Partition: 0    Leader: 2       Replicas: 2,1,0 Isr: 2,1,0</span><br></pre></td></tr></table></figure>

<p>Partition: 0【表示分区在 0 的 broker 上】</p>
</li>
<li><p>增加主题分区数量，只能增加不能减少</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost kafka3.x]# bin/kafka-topics.sh --bootstrap-server 192.168.100.100:9092 --alter --partitions 2 --topic first</span><br></pre></td></tr></table></figure>
</li>
<li><p>重新查看</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost kafka3.x]# bin/kafka-topics.sh --bootstrap-server 192.168.100.100:9092 --describe --topic first  </span><br><span class="line">Topic: first    TopicId: RO0D3TvwR8yI3TX50bRZKQ PartitionCount: 2       ReplicationFactor: 3    Configs: segment.bytes=1073741824</span><br><span class="line">        Topic: first    Partition: 0    Leader: 2       Replicas: 2,1,0 Isr: 2,1,0</span><br><span class="line">        Topic: first    Partition: 1    Leader: 0       Replicas: 0,1,2 Isr: 0,1,2</span><br></pre></td></tr></table></figure>

<p>此时有两个分区。</p>
</li>
<li><p>删除主题</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost kafka3.x]# bin/kafka-topics.sh --bootstrap-server 192.168.100.100:9092 --delete --topic first</span><br><span class="line">[root@localhost kafka3.x]#</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="生产者相关命令"><a href="#生产者相关命令" class="headerlink" title="生产者相关命令"></a>生产者相关命令</h4><p>生产者操作脚本：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost bin]# kafka-console-producer.sh</span><br></pre></td></tr></table></figure>

<p>相关参数：</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>–bootstrap-server &lt;String: server to connect to&gt;</td>
<td>连接的 Kafka Broker 主机名称和端口号</td>
</tr>
<tr>
<td>–topic &lt;String: topic&gt;</td>
<td>操作的 topic 名称</td>
</tr>
</tbody></table>
<h4 id="消费者相关命令"><a href="#消费者相关命令" class="headerlink" title="消费者相关命令"></a>消费者相关命令</h4><p>消费者操作脚本：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost bin]# kafka-console-consumer.sh</span><br></pre></td></tr></table></figure>

<p>相关参数：</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>–bootstrap-server &lt;String: server to connect to&gt;</td>
<td>连接的 Kafka Broker 主机名称和端口号</td>
</tr>
<tr>
<td>–topic &lt;String: topic&gt;</td>
<td>操作的 topic 名称</td>
</tr>
<tr>
<td>–from-beginning</td>
<td>从头开始消费</td>
</tr>
<tr>
<td>–group &lt;String: consumer group id&gt;</td>
<td>指定消费者组名称</td>
</tr>
</tbody></table>
<p><strong>生产消费示例：</strong></p>
<ul>
<li><p>生产者发送消息</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost kafka3.x]# kafka-console-producer.sh --bootstrap-server 192.168.100.100:9092 --topic first</span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">demo</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>消费者消费消息</p>
<p>默认只消费主题中新生产的数据，如果包含主题所有的历史数据，需要添加参数 <code>--from-begining</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost kafka3.x]# kafka-console-consumer.sh --bootstrap-server 192.168.100.110:9092 --topic first</span><br><span class="line">test</span><br></pre></td></tr></table></figure>

<p>消费主题中所有的历史数据：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost kafka3.x]# kafka-console-consumer.sh --bootstrap-server 192.168.100.110:9092 --topic first --from-beginning</span><br><span class="line">demo</span><br><span class="line">test</span><br><span class="line">example</span><br><span class="line">hello</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="kafka-生产者"><a href="#kafka-生产者" class="headerlink" title="kafka 生产者"></a>kafka 生产者</h2><h3 id="生产者消息发送流程"><a href="#生产者消息发送流程" class="headerlink" title="生产者消息发送流程"></a>生产者消息发送流程</h3><h4 id="发送原理"><a href="#发送原理" class="headerlink" title="发送原理"></a>发送原理</h4><p><img src="/2023/03/21/Kafka/Kafka%E7%94%9F%E4%BA%A7%E8%80%85%E5%8F%91%E9%80%81%E6%B5%81%E7%A8%8B.png" alt="Kafka生产者发送流程.png"></p>
<blockquote>
<ol>
<li><p>生产者通过 Main 线程发送消息，创建了 Producer 对象，调用 Send() 方法发送数据，根据业务需求经过拦截器对消息进行处理（一般不做处理），再由自己的序列化器进行序列化（跨节点通信），再通过分区器 Partitioner 规定每个数据发往那个分区，一个分区创建一个队列，即发往一个缓存队列中（在内存中创建），队列大小默认 32M，每一批次大小默认为 16K，发送数据时会创建批次大小，每个批次会从<code>内存池</code>中取出内存，当批次中的数据发送到 Kafka 集群中时，会将批次释放至内存池中。</p>
</li>
<li><p>再由 Sender 线程主动拉取数据，拉取数据时需要满足两个条件：</p>
<ul>
<li><strong>batch.size：只有数据积累到 batch.size 之后，sender 才会发送数据。默认 16K</strong></li>
<li><strong>linger.ms：如果数据迟迟未达到 batch.size，sender 等待 linger.ms 设置的时间到了之后就会发送数据。单位ms，默认值是 0ms，表示没有延迟。</strong></li>
</ul>
<p>发送数据到 broker 时，每个分区的数据，会以节点的形式，每一个 节点会有一个队列，如果发送给 broker 的数据没有应答，则队列最多会缓存 5 个 Request。</p>
</li>
<li><p>Selector 负责建立 Socket 连接并发送数据，broker 对于发送的数据会进行 ACK 应答，其中：</p>
<ul>
<li>0：表示生产者发送过来的数据不需要等待数据落盘应答</li>
<li>1：表示生产者发送过来的数据，Leader 收到并落盘应答</li>
<li>-1（all）：表示生产者发送过来的数据，Leader 和 ISR 队列中的所有节点收到数据落盘后应答，-1 和 all 等价</li>
</ul>
<p>如果应答成功，则会清除掉 Request 中的数据，并清空分区中的数据，如果应答失败，则会进行重试，重试的最大次数为 Integer.MAX_VALUE</p>
</li>
</ol>
</blockquote>
<h4 id="重要参数列表"><a href="#重要参数列表" class="headerlink" title="重要参数列表"></a>重要参数列表</h4><table>
<thead>
<tr>
<th>参数名称</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>bootstrap.servers</td>
<td>生产者连接集群所需的 broker 地址清单 。 例如 hadoop102:9092,hadoop103:9092,hadoop104:9092，可以设置 1 个或者多个，中间用逗号隔开。注意这里并非需要所有的 broker 地址，因为生产者从给定的 broker 里查找到其他 broker 信息</td>
</tr>
<tr>
<td>key.serializer 和 value.serializer</td>
<td><strong>指定发送消息的 key 和 value 的序列化类型（一定要写全类名）</strong></td>
</tr>
<tr>
<td>buffer.memory</td>
<td><strong>RecordAccumulator 缓冲区总大小，默认 32m</strong></td>
</tr>
<tr>
<td>batch.size</td>
<td><strong>缓冲区一批数据最大值，默认 16k。适当增加该值，可以提高吞吐量，但是如果该值设置太大，会导致数据传输延迟增加</strong></td>
</tr>
<tr>
<td>linger.ms</td>
<td><strong>如果数据迟迟未达到 batch.size，sender 等待 linger.time 之后就会发送数据。单位 ms，默认值是 0ms，表示没有延迟。生产环境建议该值大小为 5-100ms 之间</strong></td>
</tr>
<tr>
<td>acks</td>
<td>0：生产者发送过来的数据，不需要等数据落盘应答。<br>1：生产者发送过来的数据，Leader 收到数据后应答。<br>-1（all）：生产者发送过来的数据，Leader 和 ISR 队列里面的所有节点收齐数据后应答。默认值是-1，-1 和 all 是等价</td>
</tr>
<tr>
<td>max.in.flight.requests.per.connection</td>
<td>允许最多没有返回 ack 的次数，默认为 5，开启幂等性要保证该值是 1-5 的数字。</td>
</tr>
<tr>
<td>retries</td>
<td>当消息发送出现错误的时候，系统会重发消息。retries 表示重试次数。默认是 int 最大值，2147483647。 如果设置了重试，还想保证消息的有序性，需要设置 MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION&#x3D;1 否则在重试此失败消息的时候，其他的消息可能发送成功了</td>
</tr>
<tr>
<td>retry.backoff.ms</td>
<td>两次重试之间的时间间隔，默认是 100ms</td>
</tr>
<tr>
<td>enable.idempotence</td>
<td>是否开启幂等性，默认 true，开启幂等性</td>
</tr>
<tr>
<td>compression.type</td>
<td><strong>生产者发送的所有数据的压缩方式。默认是 none，也 就是不压缩。 支持压缩类型：none、gzip、snappy、lz4 和 zstd。</strong></td>
</tr>
</tbody></table>
<h3 id="异步发送-API"><a href="#异步发送-API" class="headerlink" title="异步发送 API"></a>异步发送 API</h3><h4 id="普通异步发送"><a href="#普通异步发送" class="headerlink" title="普通异步发送"></a>普通异步发送</h4><p>生产者发送时的异步指的是，数据发送到 RecordAccumulator 缓冲区中，无需等待 Sender 线程发送数据等待结果返回。</p>
<p>示例：创建 Kafka 生产者，采用异步的方式发送到 Kafka Broker</p>
<ul>
<li><p>创建工程 Kafka_GettingStart</p>
</li>
<li><p>引入依赖：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>kafka-clients<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.0.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>创建生产者 CustomProducer</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.example.kafka;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.KafkaProducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.StringSerializer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomProducer</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 1. 创建配置对象</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;192.168.100.100:9092,192.168.100.110:9092,192.168.100.120:9092&quot;</span>);</span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line">        <span class="comment">// 2. 创建 KafkaProducer 对象</span></span><br><span class="line">        <span class="comment">// try(KafkaProducer&lt;String, String&gt; kafkaProducer = new KafkaProducer&lt;&gt;(properties))&#123;&#125;</span></span><br><span class="line">        KafkaProducer&lt;String, String&gt; kafkaProducer = <span class="keyword">new</span> <span class="title class_">KafkaProducer</span>&lt;&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 调用 Send 方法</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">3</span>; i++) &#123;</span><br><span class="line">            kafkaProducer.send(<span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;&gt;(<span class="string">&quot;first&quot;</span>, <span class="string">&quot;example: &quot;</span> + i));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 4. 关闭资源</span></span><br><span class="line">        kafkaProducer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>启动消费者进行测试：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost kafka3.x]# kafka-console-consumer.sh --bootstrap-server 192.168.100.110:9092 --topic first</span><br><span class="line">example: 0</span><br><span class="line">example: 1</span><br><span class="line">example: 2</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="异步发送回调"><a href="#异步发送回调" class="headerlink" title="异步发送回调"></a>异步发送回调</h4><ul>
<li><p>添加回调</p>
<p><strong>注意：消息发送失败会自动重试，不需要在回调函数中手动重试</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.example.kafka;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.StringSerializer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomProducerCallback</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 1. 创建配置对象</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;192.168.100.100:9092,192.168.100.110:9092,192.168.100.120:9092&quot;</span>);</span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line">        <span class="comment">// 2. 创建 KafkaProducer 对象</span></span><br><span class="line">        <span class="comment">// try(KafkaProducer&lt;String, String&gt; kafkaProducer = new KafkaProducer&lt;&gt;(properties))&#123;&#125;</span></span><br><span class="line">        KafkaProducer&lt;String, String&gt; kafkaProducer = <span class="keyword">new</span> <span class="title class_">KafkaProducer</span>&lt;&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 调用 Send 方法</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">3</span>; i++) &#123;</span><br><span class="line">            kafkaProducer.send(<span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;&gt;(<span class="string">&quot;first&quot;</span>, <span class="string">&quot;example: &quot;</span> + i), <span class="keyword">new</span> <span class="title class_">Callback</span>() &#123;</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onCompletion</span><span class="params">(RecordMetadata metadata, Exception exception)</span> &#123;</span><br><span class="line">                    <span class="keyword">if</span> (exception == <span class="literal">null</span>) &#123;</span><br><span class="line">                        System.out.println(<span class="string">&quot;Topic: &quot;</span> + metadata.topic() + <span class="string">&quot;, Partition: &quot;</span> + metadata.partition());</span><br><span class="line">                    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                        exception.printStackTrace();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 4. 关闭资源</span></span><br><span class="line">        kafkaProducer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>控制台打印：</p>
<figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Topic: first, Partition: 0</span><br><span class="line">Topic: first, Partition: 0</span><br><span class="line">Topic: first, Partition: 0</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="同步发送-API"><a href="#同步发送-API" class="headerlink" title="同步发送 API"></a>同步发送 API</h3><p>生产者同步发送指的是，数据发送到 RecordAccumulator 缓冲区中，之后等待 Sender 线程发送数据到 broker ，等待结果返回。</p>
<ul>
<li><p>只需在异步发送的基础上，调用 get( )方法即可</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.example.kafka;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.StringSerializer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.ExecutionException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomProducerSync</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ExecutionException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">// 1. 创建配置对象</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;192.168.100.100:9092,192.168.100.110:9092,192.168.100.120:9092&quot;</span>);</span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line">        <span class="comment">// 2. 创建 KafkaProducer 对象</span></span><br><span class="line">        <span class="comment">// try(KafkaProducer&lt;String, String&gt; kafkaProducer = new KafkaProducer&lt;&gt;(properties))&#123;&#125;</span></span><br><span class="line">        KafkaProducer&lt;String, String&gt; kafkaProducer = <span class="keyword">new</span> <span class="title class_">KafkaProducer</span>&lt;&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 调用 Send 方法</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">3</span>; i++) &#123;</span><br><span class="line">            <span class="comment">// 同步发送</span></span><br><span class="line">            kafkaProducer.send(<span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;&gt;(<span class="string">&quot;first&quot;</span>, <span class="string">&quot;example: &quot;</span> + i)).get();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 4. 关闭资源</span></span><br><span class="line">        kafkaProducer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>测试</p>
</li>
</ul>
<h3 id="生产者分区"><a href="#生产者分区" class="headerlink" title="生产者分区"></a>生产者分区</h3><h4 id="分区优点"><a href="#分区优点" class="headerlink" title="分区优点"></a>分区优点</h4><ul>
<li><p>便于合理使用存储资源，每个 Partition 在一个 Broker 上存储，可以把海量的数据按照分区切割成一 块一块数据存储在多台 Broker 上。</p>
<p>合理控制分区的任务，可以实现负载均衡的效果</p>
</li>
<li><p>提高并行度，生产者可以以分区为单位发送数据；消费者可以以分区为单位进行消费数据</p>
</li>
</ul>
<img src="/2023/03/21/Kafka/Kafka分区优点.png" alt="Kafka分区优点.png" style="zoom:80%;">

<h4 id="生产者发送消息的分区策略"><a href="#生产者发送消息的分区策略" class="headerlink" title="生产者发送消息的分区策略"></a>生产者发送消息的分区策略</h4><p>分区策略由默认的分区器 DefaultPartitioner 决定。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * The default partitioning strategy:</span></span><br><span class="line"><span class="comment"> * &lt;ul&gt;</span></span><br><span class="line"><span class="comment"> * &lt;li&gt;If a partition is specified in the record, use it</span></span><br><span class="line"><span class="comment"> * &lt;li&gt;If no partition is specified but a key is present choose a partition based on a hash of the key</span></span><br><span class="line"><span class="comment"> * &lt;li&gt;If no partition or key is present choose the sticky partition that changes when the batch is full.</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * See KIP-480 for details about sticky partitioning.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">DefaultPartitioner</span> <span class="keyword">implements</span> <span class="title class_">Partitioner</span> &#123;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>默认的分区策略有三种情况：</p>
<ul>
<li>指明 partition 的情况下，将所有数据写入指定的分区</li>
<li>没有指明 partition 但是 key 存在，会对 key 的 hash 值与 topic 的 partition 进行取余得到 partition 值</li>
<li>既没有 partition 值又没有 key 值的情况下，Kafka 采用 Sticky Partition（黏性分区器），会随机选择一个分区，并尽可能一直使用该分区，待该分区的 batch 已满或者已完成，Kafka 再随机一个分区进行使用（和上一次的分区不同，如果此次随机选择的分区和上一个相同，则会重新选择分区）。</li>
</ul>
<p>在 ProducerRecord 中指定分区：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ProducerRecord</span>&lt;K, V&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String topic;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Integer partition;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Headers headers;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> K key;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> V value;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Long timestamp;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">ProducerRecord</span><span class="params">(String topic, Integer partition, Long timestamp, K key, V value)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>(topic, partition, timestamp, key, value, <span class="literal">null</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">ProducerRecord</span><span class="params">(String topic, Integer partition, K key, V value, Iterable&lt;Header&gt; headers)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>(topic, partition, <span class="literal">null</span>, key, value, headers);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">ProducerRecord</span><span class="params">(String topic, Integer partition, K key, V value)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>(topic, partition, <span class="literal">null</span>, key, value, <span class="literal">null</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">ProducerRecord</span><span class="params">(String topic, K key, V value)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>(topic, <span class="literal">null</span>, <span class="literal">null</span>, key, value, <span class="literal">null</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">ProducerRecord</span><span class="params">(String topic, V value)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>(topic, <span class="literal">null</span>, <span class="literal">null</span>, <span class="literal">null</span>, value, <span class="literal">null</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// ......</span></span><br></pre></td></tr></table></figure>

<p><strong>注意：通过示例时，如果初始只有一个分区，则指定的分区不存在时，程序会阻塞，因此需要确保分区的数量不止一个，方便观察分区策略</strong></p>
<p>示例一：指明 partition 的情况下，将所有数据写入指定的分区</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">3</span>; i++) &#123;</span><br><span class="line">    kafkaProducer.send(<span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;&gt;(<span class="string">&quot;first&quot;</span>,<span class="number">1</span>,<span class="string">&quot;&quot;</span>, <span class="string">&quot;example: &quot;</span> + i), <span class="keyword">new</span> <span class="title class_">Callback</span>() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onCompletion</span><span class="params">(RecordMetadata metadata, Exception exception)</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (exception == <span class="literal">null</span>) &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;Topic: &quot;</span> + metadata.topic() + <span class="string">&quot;, Partition: &quot;</span> + metadata.partition());</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                exception.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>示例二：没有指明 partition 但是 key 存在，会对 key 的 hash 值与 topic 的 partition 进行取余得到 partition 值</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">3</span>; i++) &#123;</span><br><span class="line">    kafkaProducer.send(<span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;&gt;(<span class="string">&quot;first&quot;</span>, <span class="string">&quot;c&quot;</span>, <span class="string">&quot;example: &quot;</span> + i), <span class="keyword">new</span> <span class="title class_">Callback</span>() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onCompletion</span><span class="params">(RecordMetadata metadata, Exception exception)</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (exception == <span class="literal">null</span>) &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;Topic: &quot;</span> + metadata.topic() + <span class="string">&quot;, Partition: &quot;</span> + metadata.partition());</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                exception.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="自定义分区器"><a href="#自定义分区器" class="headerlink" title="自定义分区器"></a>自定义分区器</h4><p>自定义分区器时，需要实现 Partitioner 接口，重写 partition 方法，使用自定义分区器时，需要在 Properties 中配置参数</p>
<p>MyPartitioner：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 自定义分区</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyPartitioner</span> <span class="keyword">implements</span> <span class="title class_">Partitioner</span> &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> topic The topic name</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> key The key to partition on (or null if no key)</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> keyBytes The serialized key to partition on( or null if no key)</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> value The value to partition on or null</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> valueBytes The serialized value to partition on or null</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> cluster The current cluster metadata</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">partition</span><span class="params">(String topic, Object key, <span class="type">byte</span>[] keyBytes, Object value, <span class="type">byte</span>[] valueBytes, Cluster cluster)</span> &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">msgValue</span> <span class="operator">=</span> value.toString();</span><br><span class="line">        <span class="type">int</span> <span class="variable">partition</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">if</span> (msgValue.contains(<span class="string">&quot;example&quot;</span>)) &#123;</span><br><span class="line">            partition = <span class="number">2</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            partition = <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> partition;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">configure</span><span class="params">(Map&lt;String, ?&gt; configs)</span> &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在 Properties 中配置参数：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">properties.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, <span class="string">&quot;com.example.kafka.MyPartitioner&quot;</span>);</span><br></pre></td></tr></table></figure>



<h3 id="生产者如何提高吞吐量"><a href="#生产者如何提高吞吐量" class="headerlink" title="生产者如何提高吞吐量"></a>生产者如何提高吞吐量</h3><blockquote>
<ol>
<li>batch.size：批次大小，默认 16K<ul>
<li>每次发送到 broker 的消息数据量大小</li>
</ul>
</li>
<li>linger.ms：等待时间，修改为 5 - 100ms<ul>
<li>默认 0s，只要有消息就会被发送到 broker，但是会影响效率，当 linger.ms 设置较大时，消息有延迟。</li>
</ul>
</li>
<li>compression.type：压缩 snappy<ul>
<li>对批次数据进行压缩可以提高传输量，默认 none，可配置值 gzip、snappy、 lz4 和 zstd</li>
</ul>
</li>
<li>RecordAccumulator：缓冲区大小，修改为 64M<ul>
<li>当生产者异步发送消息时，如果 RecordAccumulator 过小，会造成消息堆积，生产者端会阻塞。</li>
</ul>
</li>
</ol>
</blockquote>
<p>示例：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.example.kafka;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.KafkaProducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.Producer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.StringSerializer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 生产者提高吞吐量参数配置</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomProducerParameter</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;192.168.100.100:9092,192.168.100.110:9092,192.168.100.120:9092&quot;</span>);</span><br><span class="line"></span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// batch.size 默认 16K</span></span><br><span class="line">        properties.put(ProducerConfig.BATCH_SIZE_CONFIG, <span class="number">16384</span> * <span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// linger.ms 默认 0ms</span></span><br><span class="line">        properties.put(ProducerConfig.LINGER_MS_CONFIG, <span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// compression.type</span></span><br><span class="line">        properties.put(ProducerConfig.COMPRESSION_TYPE_CONFIG, <span class="string">&quot;snappy&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// RecordAccumulator 默认 64M</span></span><br><span class="line">        properties.put(ProducerConfig.BUFFER_MEMORY_CONFIG, <span class="number">33554432</span> * <span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">        KafkaProducer&lt;String, String&gt; kafkaProducer = <span class="keyword">new</span> <span class="title class_">KafkaProducer</span>&lt;&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">3</span>; i++) &#123;</span><br><span class="line">            kafkaProducer.send(<span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;&gt;(<span class="string">&quot;first&quot;</span>, <span class="string">&quot;example: &quot;</span> + i));</span><br><span class="line">        &#125;</span><br><span class="line">        kafkaProducer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="数据可靠性"><a href="#数据可靠性" class="headerlink" title="数据可靠性"></a>数据可靠性</h3><p><strong>ACK 应答级别：</strong></p>
<ul>
<li>0：表示生产者发送过来的数据不需要等待数据落盘应答</li>
<li>1：表示生产者发送过来的数据，Leader 收到并落盘应答</li>
<li>-1（all）：表示生产者发送过来的数据，Leader 和 ISR 队列中的所有节点收到数据落盘后应答，-1 和 all 等价</li>
</ul>
<p><img src="/2023/03/21/Kafka/Kafka%E7%94%9F%E4%BA%A7%E8%80%85%E5%8F%91%E9%80%81%E6%B5%81%E7%A8%8B.png" alt="Kafka生产者发送流程.png"></p>
<p>ACK 应答级别：</p>
<ul>
<li><p>0：表示生产者发送过来的数据不需要等待数据落盘应答</p>
<p><strong>如果 Leader 收到数据后，尚且没有落盘，此时 Leader 挂掉，那么数据就会丢失。</strong></p>
<img src="/2023/03/21/Kafka/ACK应答级别0.png" alt="ACK应答级别.0png" style="zoom:67%;">
</li>
<li><p>1：表示生产者发送过来的数据，Leader 收到并落盘应答</p>
<p><strong>应答完成后，还没有同步副本，此时 Leader 挂掉，从剩余的 Follower 中选出 Leader，新的 Leader 不会收到消息，因为生产者认为已经发送成功了，会导致数据丢失。</strong></p>
<img src="/2023/03/21/Kafka/ACK 应答级别1.png" alt="ACK 应答级别1.png" style="zoom: 80%;">
</li>
<li><p>-1（all）：表示生产者发送过来的数据，Leader 和 ISR 队列中的所有节点收到数据落盘后应答，-1 和 all 等价</p>
<p>如果 Leader 收到数据，所有 Follower 都开始同步数据， 但有一个 Follower，因为某种故障，迟迟不能与 Leader 进行同步，这样就会导致 Leader 不能应答，进而因为一个 Follower 挂掉导致整个集群瘫痪。</p>
<p><strong>因此 Leader 维护了一个动态的 in-sync replica set（ISR），意为和 Leader 保持同步的 Follower + Leader 集合（leader：0，isr:0,1,2）。如果 Follower 长时间未向Leader 发送通信请求或同步数据，则该 Follower 将被踢出 ISR。该时间阈值由 replica.lag.time.max.ms 参数设定，默认 30s。这样就不用等待长期联系不上或者已经故障的节点。</strong></p>
<img src="/2023/03/21/Kafka/ACK 应答级别all.png" alt="image-20230607222025022" style="zoom: 80%;"></li>
</ul>
<p>需要注意的是：如果分区副本设置为 1 个，或者 ISR 里应答的最小副本数量 （ min.insync.replicas 默认为1）设置为1，和 ack &#x3D; 1 的效果是一样的，仍然有丢数的风险（leader：0，isr:0）</p>
<p><strong>因此：数据完全可靠条件 &#x3D; ACK 级别设置为 -1 + 分区副本大于等于 2 + ISR 里应答的最小副本数量大于等于 2</strong></p>
<p>可靠性总结：</p>
<ul>
<li>acks &#x3D; 0，生产者发送数据过来后，不需要等待数据落盘应答，可靠性差，效率高</li>
<li>acks &#x3D; 1，生产者发送过来数据 Leader 应答落盘，可靠性中等，效率中等</li>
<li>acks &#x3D; -1，生产者发送过来数据 Leader 和 ISR 队列里面所有 Follwer 应答，可靠性高，效率低 </li>
<li>在生产环境中，acks&#x3D;0 很少使用；acks&#x3D;1，一般用于传输普通日志，允许丢个别数据；acks&#x3D;-1，一般用于传输和钱相关的数据， 对可靠性要求比较高的场景。</li>
</ul>
<p>示例：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.example.kafka;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.KafkaProducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.StringSerializer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomProducerACK</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line"></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;192.168.100.100:9092,192.168.100.110:9092,192.168.100.120:9092&quot;</span>);</span><br><span class="line"></span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// ACK 应答级别</span></span><br><span class="line">        properties.put(ProducerConfig.ACKS_CONFIG, <span class="string">&quot;all&quot;</span>);</span><br><span class="line">        <span class="comment">// 重试次数 retries，默认 2147483647</span></span><br><span class="line">        properties.put(ProducerConfig.RETRIES_CONFIG, <span class="number">3</span>);</span><br><span class="line"></span><br><span class="line">        KafkaProducer&lt;String, String&gt; kafkaProducer = <span class="keyword">new</span> <span class="title class_">KafkaProducer</span>&lt;&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">3</span>; i++) &#123;</span><br><span class="line">            kafkaProducer.send(<span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;&gt;(<span class="string">&quot;first&quot;</span>, <span class="string">&quot;example: &quot;</span> + i));</span><br><span class="line">        &#125;</span><br><span class="line">        kafkaProducer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="数据去重"><a href="#数据去重" class="headerlink" title="数据去重"></a>数据去重</h3><p><strong>数据重复：</strong>当应答级别为 all ，并且 Leader 和所有 Follower 都落盘后，Leader 还未应答，便已经挂掉，此时重新选举出 Leader 后，生产者重新发送消息，便会造成数据的重复。</p>
<img src="/2023/03/21/Kafka/ACK应答级别为all时数据重复.png" alt="ACK应答级别为all时数据重复.png" style="zoom:67%;">

<h4 id="数据传递语义"><a href="#数据传递语义" class="headerlink" title="数据传递语义"></a>数据传递语义</h4><blockquote>
<ul>
<li><p>至少一次（At Least Once）&#x3D; ACK 级别设置为 -1 + 分区副本大于等于 2 + ISR 里应答的最小副本数量大于等于2 【数据不丢】</p>
</li>
<li><p>最多一次（At Most Once）&#x3D; ACK 级别设置为 0 【数据不重】</p>
</li>
<li><p>总结： At Least Once 可以保证数据不丢失，但是不能保证数据不重复； At Most Once 可以保证数据不重复，但是不能保证数据不丢失。</p>
</li>
<li><p>精确一次（Exactly Once）：对于一些非常重要的信息，比如和钱相关的数据，要求数据既不能重复也不丢失。 </p>
</li>
<li><p>Kafka 0.11 版本以后，引入了一项重大特性：<strong>幂等性和事务</strong></p>
</li>
</ul>
</blockquote>
<h4 id="幂等性"><a href="#幂等性" class="headerlink" title="幂等性"></a>幂等性</h4><p><strong>幂等性原理：</strong></p>
<p>幂等性就是指 Producer 不论向 Broker 发送多少次重复数据，Broker 端都只会持久化一条，保证了不重复</p>
<p>精确一次（Exactly Once） &#x3D;  幂等性 + 至少一次（ ack&#x3D;-1 + 分区副本数 &gt;&#x3D; 2 + ISR 最小副本数量 &gt;&#x3D; 2）</p>
<p>重复数据的判断标准：具有相同主键（key）的消息提交时，Broker 只会持久化一条。其中：</p>
<ul>
<li>PID 是 Kafka 每次重启都会分配一个新的</li>
<li>Partition 表示分区号</li>
<li>Sequence Number是单调自增的</li>
</ul>
<p><strong>所以幂等性只能保证的是在单分区单会话内不重复，如果要保证不重复，需要事务支持。</strong></p>
<p>如以下两个消息分别发送两个不同的分区。</p>
<p><img src="/2023/03/21/Kafka/%E5%B9%82%E7%AD%89%E6%80%A7%E5%8E%9F%E7%90%86.png" alt="幂等性原理.png"></p>
<p><strong>使用幂等性：</strong>开启参数 enable.idempotence 默认为 true，false 关闭</p>
<h4 id="生产者事务"><a href="#生产者事务" class="headerlink" title="生产者事务"></a>生产者事务</h4><p><strong>Kafka 事务原理：</strong></p>
<p><strong>注意：开启事务，必须开启幂等性</strong></p>
<p><img src="/2023/03/21/Kafka/%E7%94%9F%E4%BA%A7%E8%80%85%E4%BA%8B%E5%8A%A1%E5%8E%9F%E7%90%86.png" alt="生产者事务原理.png"></p>
<h4 id="相关-API"><a href="#相关-API" class="headerlink" title="相关 API"></a>相关 API</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">KafkaProducer</span>&lt;K, V&gt; <span class="keyword">implements</span> <span class="title class_">Producer</span>&lt;K, V&gt; &#123;</span><br><span class="line">    <span class="comment">// 1 初始化事务</span></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">initTransactions</span><span class="params">()</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 2 开启事务</span></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">beginTransaction</span><span class="params">()</span> <span class="keyword">throws</span> ProducerFencedException;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 3 在事务内提交已经消费的偏移量（主要用于消费者）</span></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">sendOffsetsToTransaction</span><span class="params">(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets, String consumerGroupId)</span> <span class="keyword">throws</span>   ProducerFencedException;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 4 提交事务</span></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">commitTransaction</span><span class="params">()</span> <span class="keyword">throws</span> ProducerFencedException;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 5 放弃事务（类似于回滚事务的操作）</span></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">abortTransaction</span><span class="params">()</span> <span class="keyword">throws</span> ProducerFencedException;</span><br></pre></td></tr></table></figure>

<p>示例：通过事务保证消息不重复也不丢失</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.example.kafka;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.KafkaProducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.StringSerializer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomProducerTransaction</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line"></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;192.168.100.100:9092,192.168.100.110:9092,192.168.100.120:9092&quot;</span>);</span><br><span class="line"></span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置事务ID</span></span><br><span class="line">        properties.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, <span class="string">&quot;transaction_id_0&quot;</span>);</span><br><span class="line"></span><br><span class="line">        KafkaProducer&lt;String, String&gt; kafkaProducer = <span class="keyword">new</span> <span class="title class_">KafkaProducer</span>&lt;&gt;(properties);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 初始化事务</span></span><br><span class="line">        kafkaProducer.initTransactions();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 开启事务</span></span><br><span class="line">        kafkaProducer.beginTransaction();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">3</span>; i++) &#123;</span><br><span class="line">                kafkaProducer.send(<span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;&gt;(<span class="string">&quot;first&quot;</span>, <span class="string">&quot;example: &quot;</span> + i));</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 模拟 Kafka 异常</span></span><br><span class="line">            <span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">1</span> / <span class="number">0</span>;</span><br><span class="line">            <span class="comment">// 提交事务</span></span><br><span class="line">            kafkaProducer.commitTransaction();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">            <span class="comment">// 回滚事务</span></span><br><span class="line">            kafkaProducer.abortTransaction();</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            kafkaProducer.close();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="数据乱序"><a href="#数据乱序" class="headerlink" title="数据乱序"></a>数据乱序</h3><blockquote>
<ul>
<li><p>kafka 在 1.x 版本之前保证数据单分区有序，条件如下：</p>
<p>max.in.flight.requests.per.connection &#x3D; 1（不需要考虑是否开启幂等性）。</p>
</li>
<li><p>kafka 在 1.x 及以后版本保证数据单分区有序，条件如下：</p>
<ul>
<li>未开启幂等性： max.in.flight.requests.per.connection 需要设置为 1</li>
<li>开启幂等性： max.in.flight.requests.per.connection 需要设置小于等于 5<ul>
<li>说明：因为在 kafka1.x 以后，启用幂等后，kafka 服务端会缓存 producer 发来的最近 5 个 request 的元数据， 故无论如何，都可以保证最近 5 个request 的数据都是有序的</li>
</ul>
</li>
</ul>
</li>
</ul>
</blockquote>
<p>数据乱序：</p>
<p>如下示例，Request1 和 Request2 发送成功会数据会落盘，Request3 因故障没有发送成功，后面的 Request4 和 Request5 却不会落盘，当 Request3 发送并落盘后，Request4 和 Request5 才会落盘，以此保证数据的有序性。</p>
<p><img src="/2023/03/21/Kafka/%E5%8D%95%E5%88%86%E5%8C%BA%E6%95%B0%E6%8D%AE%E6%9C%89%E5%BA%8F.png" alt="单分区数据有序.png"></p>
<h3 id="数据有序"><a href="#数据有序" class="headerlink" title="数据有序"></a>数据有序</h3><p>对于单分区内保证数据有序，但多分区，分区与分区之间是无序的，如果要保证多分区内数据有序，则可以在消费端进行数据的重排序。</p>
<img src="/2023/03/21/Kafka/数据有序.png" alt="数据有序.png" style="zoom:67%;">

<h2 id="Kafka-Broker"><a href="#Kafka-Broker" class="headerlink" title="Kafka Broker"></a>Kafka Broker</h2><h3 id="Kafka-Broker-工作流程"><a href="#Kafka-Broker-工作流程" class="headerlink" title="Kafka Broker 工作流程"></a>Kafka Broker 工作流程</h3><h4 id="Zookeeper-存储的-Kafka-信息"><a href="#Zookeeper-存储的-Kafka-信息" class="headerlink" title="Zookeeper 存储的 Kafka 信息"></a>Zookeeper 存储的 Kafka 信息</h4><p>在 Zookeeper 中查看 kafka 的信息</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>





<h4 id="Kafka-Broker-整体工作流程"><a href="#Kafka-Broker-整体工作流程" class="headerlink" title="Kafka Broker 整体工作流程"></a>Kafka Broker 整体工作流程</h4><h4 id="Broker-重要参数"><a href="#Broker-重要参数" class="headerlink" title="Broker 重要参数"></a>Broker 重要参数</h4><h3 id="节点服役与退役"><a href="#节点服役与退役" class="headerlink" title="节点服役与退役"></a>节点服役与退役</h3><h4 id="服役新节点"><a href="#服役新节点" class="headerlink" title="服役新节点"></a>服役新节点</h4><h4 id="退役旧节点"><a href="#退役旧节点" class="headerlink" title="退役旧节点"></a>退役旧节点</h4><h3 id="Kafka-副本"><a href="#Kafka-副本" class="headerlink" title="Kafka 副本"></a>Kafka 副本</h3><h4 id="副本基本信息"><a href="#副本基本信息" class="headerlink" title="副本基本信息"></a>副本基本信息</h4><h4 id="Leader-选举流程"><a href="#Leader-选举流程" class="headerlink" title="Leader 选举流程"></a>Leader 选举流程</h4><h4 id="Leader-和-Follower-故障处理细节"><a href="#Leader-和-Follower-故障处理细节" class="headerlink" title="Leader 和 Follower 故障处理细节"></a>Leader 和 Follower 故障处理细节</h4><h4 id="分区副本分配"><a href="#分区副本分配" class="headerlink" title="分区副本分配"></a>分区副本分配</h4><h4 id="手动调整分区副本存储"><a href="#手动调整分区副本存储" class="headerlink" title="手动调整分区副本存储"></a>手动调整分区副本存储</h4><h4 id="Leader-Partition-负载平衡"><a href="#Leader-Partition-负载平衡" class="headerlink" title="Leader Partition 负载平衡"></a>Leader Partition 负载平衡</h4><h4 id="增加副本因子"><a href="#增加副本因子" class="headerlink" title="增加副本因子"></a>增加副本因子</h4><h3 id="文件存储"><a href="#文件存储" class="headerlink" title="文件存储"></a>文件存储</h3><h4 id="文件存储机制"><a href="#文件存储机制" class="headerlink" title="文件存储机制"></a>文件存储机制</h4><h4 id="文件清除策略"><a href="#文件清除策略" class="headerlink" title="文件清除策略"></a>文件清除策略</h4><h3 id="高效读写数据"><a href="#高效读写数据" class="headerlink" title="高效读写数据"></a>高效读写数据</h3><h2 id="Kafka-消费者"><a href="#Kafka-消费者" class="headerlink" title="Kafka 消费者"></a>Kafka 消费者</h2><h2 id="Kafka-Eagle-监控"><a href="#Kafka-Eagle-监控" class="headerlink" title="Kafka-Eagle 监控"></a>Kafka-Eagle 监控</h2><p>Kafka-Eagle 框架可以监控 Kafka 集群的整体运行情况，在生产环境中经常使用</p>
<h3 id="MySQL-环境准备"><a href="#MySQL-环境准备" class="headerlink" title="MySQL 环境准备"></a>MySQL 环境准备</h3><p>Kafka-Eagle 的安装依赖于 MySQL，MySQL 主要用来存储可视化展示的数据。</p>
<ul>
<li><p>下载并解压相应安装包</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost mysql5.7]# pwd</span><br><span class="line">/opt/mysql5.7</span><br><span class="line">[root@localhost mysql5.7]# ll</span><br><span class="line">总用量 185388</span><br><span class="line">-rw-r--r--. 1 root root    277604 6月   9 13:32 mysql-community-common-5.7.16-1.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   2237116 6月   9 13:32 mysql-community-libs-5.7.16-1.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root   2112700 6月   9 13:32 mysql-community-libs-compat-5.7.16-1.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root  25034716 6月   9 13:32 mysql-community-client-5.7.16-1.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root 159295840 6月   9 13:32 mysql-community-server-5.7.16-1.el7.x86_64.rpm</span><br><span class="line">-rw-r--r--. 1 root root    872303 6月   9 13:32 mysql-connector-java-5.1.27-bin.jar</span><br></pre></td></tr></table></figure>
</li>
<li><p>卸载自带的 mysql-lib</p>
<ul>
<li><p>如果是虚拟机：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost mysql5.7]# rpm -qa | grep -i -E mysql\|mariadb | xargs -n1 sudo rpm -e --nodeps</span><br></pre></td></tr></table></figure>
</li>
<li><p>如果是阿里云服务器（安装的是 Linux 最小版）</p>
<p>卸载 MySQL 依赖：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost mysql5.7]# yum remove mysql-libs</span><br></pre></td></tr></table></figure>

<p>下载编译相关依赖并安装：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost mysql5.7]# yum install libaio</span><br><span class="line">[root@localhost mysql5.7]# yum install autoconf</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>安装依赖</p>
<ul>
<li><p>安装 MySQL 依赖：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost mysql5.7]# rpm -ivh mysql-community-common-5.7.16-1.el7.x86_64.rpm</span><br><span class="line">[root@localhost mysql5.7]# rpm -ivh mysql-community-libs-5.7.16-1.el7.x86_64.rpm</span><br><span class="line">[root@localhost mysql5.7]# rpm -ivh mysql-community-libs-compat-5.7.16-1.el7.x86_64.rpm</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装 MySQL-Client</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost mysql5.7]# rpm -ivh mysql-community-client-5.7.16-1.el7.x86_64.rpm</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装 MySQL-Server</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost mysql5.7]# rpm -ivh mysql-community-server-5.7.16-1.el7.x86_64.rpm</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>启动 MySQL</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost mysql5.7]# systemctl start mysqld</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看 MySQL 密码</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost mysql5.7]# cat /var/log/mysqld.log | grep password</span><br><span class="line">2023-06-09T05:53:49.161800Z 1 [Note] A temporary password is generated for root@localhost: tQlEHZzjF5_c</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置密码</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">使用上一步查询到的密码（带单引号）登录 MySQL</span></span><br><span class="line">[root@localhost mysql5.7]# mysql -uroot -p&#x27;tQlEHZzjF5_c&#x27;</span><br></pre></td></tr></table></figure>
</li>
<li><p>更改密码策略</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash"><span class="built_in">set</span> global validate_password_length=4;</span></span><br><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash"><span class="built_in">set</span> global validate_password_policy=0;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>重新设置密码</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash"><span class="built_in">set</span> password=password(<span class="string">&quot;root&quot;</span>);</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>设置 MySQL 远程连接</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash">select user,host from user;</span></span><br><span class="line">+-----------+-----------+</span><br><span class="line">| user      | host      |</span><br><span class="line">+-----------+-----------+</span><br><span class="line">| mysql.sys | localhost |</span><br><span class="line">| root      | localhost |</span><br><span class="line">+-----------+-----------+</span><br><span class="line">2 rows in set (0.00 sec)</span><br><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash">update user <span class="built_in">set</span> host = <span class="string">&#x27;%&#x27;</span> <span class="built_in">where</span> user = <span class="string">&#x27;root&#x27;</span>;</span></span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line">Rows matched: 1  Changed: 1  Warnings: 0</span><br></pre></td></tr></table></figure>
</li>
<li><p>刷新权限并退出</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash">flush privileges;</span></span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"><span class="meta prompt_">mysql&gt; </span><span class="language-bash">quit</span></span><br><span class="line">Bye</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="Kafka-Kraft-模式"><a href="#Kafka-Kraft-模式" class="headerlink" title="Kafka-Kraft 模式"></a>Kafka-Kraft 模式</h2><h1 id="Kafka-集成"><a href="#Kafka-集成" class="headerlink" title="Kafka 集成"></a>Kafka 集成</h1><h2 id="集成-Flume"><a href="#集成-Flume" class="headerlink" title="集成 Flume"></a>集成 Flume</h2><h2 id="集成-Flink"><a href="#集成-Flink" class="headerlink" title="集成 Flink"></a>集成 Flink</h2><h2 id="集成-SpringBoot"><a href="#集成-SpringBoot" class="headerlink" title="集成 SpringBoot"></a>集成 SpringBoot</h2><h2 id="集成-Spark"><a href="#集成-Spark" class="headerlink" title="集成 Spark"></a>集成 Spark</h2><h1 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h1><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><h2 id="生产者源码"><a href="#生产者源码" class="headerlink" title="生产者源码"></a>生产者源码</h2><h2 id="消费者源码"><a href="#消费者源码" class="headerlink" title="消费者源码"></a>消费者源码</h2><h2 id="服务器源码"><a href="#服务器源码" class="headerlink" title="服务器源码"></a>服务器源码</h2><h1 id="生产调优"><a href="#生产调优" class="headerlink" title="生产调优"></a>生产调优</h1><h2 id="Kafka-硬件配置选择"><a href="#Kafka-硬件配置选择" class="headerlink" title="Kafka 硬件配置选择"></a>Kafka 硬件配置选择</h2><h2 id="Kafka-生产者"><a href="#Kafka-生产者" class="headerlink" title="Kafka 生产者"></a>Kafka 生产者</h2><h2 id="kafka-Broker"><a href="#kafka-Broker" class="headerlink" title="kafka Broker"></a>kafka Broker</h2><h2 id="Kafka-消费者-1"><a href="#Kafka-消费者-1" class="headerlink" title="Kafka 消费者"></a>Kafka 消费者</h2><h2 id="kafka-总体"><a href="#kafka-总体" class="headerlink" title="kafka 总体"></a>kafka 总体</h2>
    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2023/03/20/RabbitMQ/" rel="prev" title="RabbitMQ">
      <i class="fa fa-chevron-left"></i> RabbitMQ
    </a></div>
      <div class="post-nav-item">
    <a href="/2023/03/22/RocketMQ/" rel="next" title="RocketMQ">
      RocketMQ <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#kafka-%E5%85%A5%E9%97%A8"><span class="nav-number">1.</span> <span class="nav-text">kafka 入门</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka-%E6%A6%82%E8%BF%B0"><span class="nav-number">1.1.</span> <span class="nav-text">Kafka 概述</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9A%E4%B9%89"><span class="nav-number">1.1.1.</span> <span class="nav-text">定义</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97"><span class="nav-number">1.1.2.</span> <span class="nav-text">消息队列</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BC%A0%E7%BB%9F%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="nav-number">1.1.2.1.</span> <span class="nav-text">传统消息队列的应用场景</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%A8%A1%E5%BC%8F"><span class="nav-number">1.1.2.2.</span> <span class="nav-text">消息队列的两种模式</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%82%B9%E5%AF%B9%E7%82%B9%E6%A8%A1%E5%BC%8F"><span class="nav-number">1.1.2.2.1.</span> <span class="nav-text">点对点模式</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%8F%91%E5%B8%83-x2F-%E8%AE%A2%E9%98%85%E6%A8%A1%E5%BC%8F"><span class="nav-number">1.1.2.2.2.</span> <span class="nav-text">发布 &#x2F; 订阅模式</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka-%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84"><span class="nav-number">1.1.3.</span> <span class="nav-text">Kafka 基础架构</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka-%E5%85%A5%E9%97%A8%E7%A4%BA%E4%BE%8B"><span class="nav-number">1.2.</span> <span class="nav-text">Kafka 入门示例</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%A2%84%E5%85%88%E5%87%86%E5%A4%87"><span class="nav-number">1.2.1.</span> <span class="nav-text">预先准备</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%85%8D%E7%BD%AE-Java-%E7%8E%AF%E5%A2%83"><span class="nav-number">1.2.1.1.</span> <span class="nav-text">配置 Java 环境</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%85%8D%E7%BD%AE%E9%9B%86%E7%BE%A4%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95"><span class="nav-number">1.2.1.2.</span> <span class="nav-text">配置集群免密登录</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%88%86%E5%8F%91%E8%84%9A%E6%9C%AC-xsync-sh"><span class="nav-number">1.2.1.3.</span> <span class="nav-text">分发脚本 xsync.sh</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9F%A5%E7%9C%8B-Java-%E8%BF%9B%E7%A8%8B-jspall-sh"><span class="nav-number">1.2.1.4.</span> <span class="nav-text">查看 Java 进程  jspall.sh</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%89%E8%A3%85%E6%AD%A5%E9%AA%A4"><span class="nav-number">1.2.2.</span> <span class="nav-text">安装步骤</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%89%E8%A3%85-Zookeeper"><span class="nav-number">1.2.2.1.</span> <span class="nav-text">安装 Zookeeper</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%8D%95%E6%9C%BA%E7%89%88"><span class="nav-number">1.2.2.1.1.</span> <span class="nav-text">单机版</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%9B%86%E7%BE%A4%E7%89%88"><span class="nav-number">1.2.2.1.2.</span> <span class="nav-text">集群版</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%89%E8%A3%85-Kafka"><span class="nav-number">1.2.2.2.</span> <span class="nav-text">安装 Kafka</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%93%8D%E4%BD%9C"><span class="nav-number">1.2.3.</span> <span class="nav-text">命令行操作</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%BB%E9%A2%98%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4"><span class="nav-number">1.2.3.1.</span> <span class="nav-text">主题相关命令</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4"><span class="nav-number">1.2.3.2.</span> <span class="nav-text">生产者相关命令</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4"><span class="nav-number">1.2.3.3.</span> <span class="nav-text">消费者相关命令</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#kafka-%E7%94%9F%E4%BA%A7%E8%80%85"><span class="nav-number">1.3.</span> <span class="nav-text">kafka 生产者</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E6%B5%81%E7%A8%8B"><span class="nav-number">1.3.1.</span> <span class="nav-text">生产者消息发送流程</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8F%91%E9%80%81%E5%8E%9F%E7%90%86"><span class="nav-number">1.3.1.1.</span> <span class="nav-text">发送原理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%87%8D%E8%A6%81%E5%8F%82%E6%95%B0%E5%88%97%E8%A1%A8"><span class="nav-number">1.3.1.2.</span> <span class="nav-text">重要参数列表</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BC%82%E6%AD%A5%E5%8F%91%E9%80%81-API"><span class="nav-number">1.3.2.</span> <span class="nav-text">异步发送 API</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%99%AE%E9%80%9A%E5%BC%82%E6%AD%A5%E5%8F%91%E9%80%81"><span class="nav-number">1.3.2.1.</span> <span class="nav-text">普通异步发送</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BC%82%E6%AD%A5%E5%8F%91%E9%80%81%E5%9B%9E%E8%B0%83"><span class="nav-number">1.3.2.2.</span> <span class="nav-text">异步发送回调</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%90%8C%E6%AD%A5%E5%8F%91%E9%80%81-API"><span class="nav-number">1.3.3.</span> <span class="nav-text">同步发送 API</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E5%88%86%E5%8C%BA"><span class="nav-number">1.3.4.</span> <span class="nav-text">生产者分区</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%88%86%E5%8C%BA%E4%BC%98%E7%82%B9"><span class="nav-number">1.3.4.1.</span> <span class="nav-text">分区优点</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF%E7%9A%84%E5%88%86%E5%8C%BA%E7%AD%96%E7%95%A5"><span class="nav-number">1.3.4.2.</span> <span class="nav-text">生产者发送消息的分区策略</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89%E5%88%86%E5%8C%BA%E5%99%A8"><span class="nav-number">1.3.4.3.</span> <span class="nav-text">自定义分区器</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E5%A6%82%E4%BD%95%E6%8F%90%E9%AB%98%E5%90%9E%E5%90%90%E9%87%8F"><span class="nav-number">1.3.5.</span> <span class="nav-text">生产者如何提高吞吐量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%8F%AF%E9%9D%A0%E6%80%A7"><span class="nav-number">1.3.6.</span> <span class="nav-text">数据可靠性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%8E%BB%E9%87%8D"><span class="nav-number">1.3.7.</span> <span class="nav-text">数据去重</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E4%BC%A0%E9%80%92%E8%AF%AD%E4%B9%89"><span class="nav-number">1.3.7.1.</span> <span class="nav-text">数据传递语义</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%B9%82%E7%AD%89%E6%80%A7"><span class="nav-number">1.3.7.2.</span> <span class="nav-text">幂等性</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E4%BA%8B%E5%8A%A1"><span class="nav-number">1.3.7.3.</span> <span class="nav-text">生产者事务</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%9B%B8%E5%85%B3-API"><span class="nav-number">1.3.7.4.</span> <span class="nav-text">相关 API</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E4%B9%B1%E5%BA%8F"><span class="nav-number">1.3.8.</span> <span class="nav-text">数据乱序</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E6%9C%89%E5%BA%8F"><span class="nav-number">1.3.9.</span> <span class="nav-text">数据有序</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka-Broker"><span class="nav-number">1.4.</span> <span class="nav-text">Kafka Broker</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka-Broker-%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B"><span class="nav-number">1.4.1.</span> <span class="nav-text">Kafka Broker 工作流程</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Zookeeper-%E5%AD%98%E5%82%A8%E7%9A%84-Kafka-%E4%BF%A1%E6%81%AF"><span class="nav-number">1.4.1.1.</span> <span class="nav-text">Zookeeper 存储的 Kafka 信息</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Kafka-Broker-%E6%95%B4%E4%BD%93%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B"><span class="nav-number">1.4.1.2.</span> <span class="nav-text">Kafka Broker 整体工作流程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Broker-%E9%87%8D%E8%A6%81%E5%8F%82%E6%95%B0"><span class="nav-number">1.4.1.3.</span> <span class="nav-text">Broker 重要参数</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%8A%82%E7%82%B9%E6%9C%8D%E5%BD%B9%E4%B8%8E%E9%80%80%E5%BD%B9"><span class="nav-number">1.4.2.</span> <span class="nav-text">节点服役与退役</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9C%8D%E5%BD%B9%E6%96%B0%E8%8A%82%E7%82%B9"><span class="nav-number">1.4.2.1.</span> <span class="nav-text">服役新节点</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%80%80%E5%BD%B9%E6%97%A7%E8%8A%82%E7%82%B9"><span class="nav-number">1.4.2.2.</span> <span class="nav-text">退役旧节点</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka-%E5%89%AF%E6%9C%AC"><span class="nav-number">1.4.3.</span> <span class="nav-text">Kafka 副本</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%89%AF%E6%9C%AC%E5%9F%BA%E6%9C%AC%E4%BF%A1%E6%81%AF"><span class="nav-number">1.4.3.1.</span> <span class="nav-text">副本基本信息</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Leader-%E9%80%89%E4%B8%BE%E6%B5%81%E7%A8%8B"><span class="nav-number">1.4.3.2.</span> <span class="nav-text">Leader 选举流程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Leader-%E5%92%8C-Follower-%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E7%BB%86%E8%8A%82"><span class="nav-number">1.4.3.3.</span> <span class="nav-text">Leader 和 Follower 故障处理细节</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%88%86%E5%8C%BA%E5%89%AF%E6%9C%AC%E5%88%86%E9%85%8D"><span class="nav-number">1.4.3.4.</span> <span class="nav-text">分区副本分配</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%89%8B%E5%8A%A8%E8%B0%83%E6%95%B4%E5%88%86%E5%8C%BA%E5%89%AF%E6%9C%AC%E5%AD%98%E5%82%A8"><span class="nav-number">1.4.3.5.</span> <span class="nav-text">手动调整分区副本存储</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Leader-Partition-%E8%B4%9F%E8%BD%BD%E5%B9%B3%E8%A1%A1"><span class="nav-number">1.4.3.6.</span> <span class="nav-text">Leader Partition 负载平衡</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A2%9E%E5%8A%A0%E5%89%AF%E6%9C%AC%E5%9B%A0%E5%AD%90"><span class="nav-number">1.4.3.7.</span> <span class="nav-text">增加副本因子</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8"><span class="nav-number">1.4.4.</span> <span class="nav-text">文件存储</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6"><span class="nav-number">1.4.4.1.</span> <span class="nav-text">文件存储机制</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%96%87%E4%BB%B6%E6%B8%85%E9%99%A4%E7%AD%96%E7%95%A5"><span class="nav-number">1.4.4.2.</span> <span class="nav-text">文件清除策略</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%AB%98%E6%95%88%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE"><span class="nav-number">1.4.5.</span> <span class="nav-text">高效读写数据</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka-%E6%B6%88%E8%B4%B9%E8%80%85"><span class="nav-number">1.5.</span> <span class="nav-text">Kafka 消费者</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka-Eagle-%E7%9B%91%E6%8E%A7"><span class="nav-number">1.6.</span> <span class="nav-text">Kafka-Eagle 监控</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#MySQL-%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87"><span class="nav-number">1.6.1.</span> <span class="nav-text">MySQL 环境准备</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka-Kraft-%E6%A8%A1%E5%BC%8F"><span class="nav-number">1.7.</span> <span class="nav-text">Kafka-Kraft 模式</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Kafka-%E9%9B%86%E6%88%90"><span class="nav-number">2.</span> <span class="nav-text">Kafka 集成</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%9B%86%E6%88%90-Flume"><span class="nav-number">2.1.</span> <span class="nav-text">集成 Flume</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%9B%86%E6%88%90-Flink"><span class="nav-number">2.2.</span> <span class="nav-text">集成 Flink</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%9B%86%E6%88%90-SpringBoot"><span class="nav-number">2.3.</span> <span class="nav-text">集成 SpringBoot</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%9B%86%E6%88%90-Spark"><span class="nav-number">2.4.</span> <span class="nav-text">集成 Spark</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90"><span class="nav-number">3.</span> <span class="nav-text">源码解析</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87"><span class="nav-number">3.1.</span> <span class="nav-text">环境准备</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E6%BA%90%E7%A0%81"><span class="nav-number">3.2.</span> <span class="nav-text">生产者源码</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E6%BA%90%E7%A0%81"><span class="nav-number">3.3.</span> <span class="nav-text">消费者源码</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%BA%90%E7%A0%81"><span class="nav-number">3.4.</span> <span class="nav-text">服务器源码</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%94%9F%E4%BA%A7%E8%B0%83%E4%BC%98"><span class="nav-number">4.</span> <span class="nav-text">生产调优</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka-%E7%A1%AC%E4%BB%B6%E9%85%8D%E7%BD%AE%E9%80%89%E6%8B%A9"><span class="nav-number">4.1.</span> <span class="nav-text">Kafka 硬件配置选择</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka-%E7%94%9F%E4%BA%A7%E8%80%85"><span class="nav-number">4.2.</span> <span class="nav-text">Kafka 生产者</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#kafka-Broker"><span class="nav-number">4.3.</span> <span class="nav-text">kafka Broker</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka-%E6%B6%88%E8%B4%B9%E8%80%85-1"><span class="nav-number">4.4.</span> <span class="nav-text">Kafka 消费者</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#kafka-%E6%80%BB%E4%BD%93"><span class="nav-number">4.5.</span> <span class="nav-text">kafka 总体</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Fei</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">47</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Fei</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

</body>
</html>
